---
layout: post
title: Release of a multimodal autonomous driving dataset in a simulation environment
date: 2024-09-01 11:12:00-0400
description: Collected by CARLA-ADA from CARLA 0.9.15
tags: AD dataset
categories: code
thumbnail: assets/img/blog/other/0000017576.png
related_posts: false
published: true
---

The CARLA-ADA Dataset is a comprehensive multimodal autonomous driving dataset collected using our custom data acquisition tool in the CARLA simulator. The dataset encompasses diverse driving scenarios across urban, rural, highway, and suburban environments, providing a rich variety of real-world driving situations.

The dataset features synchronized image and 3D LiDAR point cloud data, capturing five distinct object classes: cars, trucks, pedestrians, bicycles, and buses. With a total size of 35GB, this dataset offers high-quality annotated data suitable for various autonomous driving perception tasks, including object detection, semantic segmentation, and multi-modal fusion research.

Key Features:
- Multi-environment data collection: urban, rural, highway, and suburban scenes
- Multi-modality: camera images and LiDAR point clouds
- Five object classes with careful annotations
- Diverse weather and lighting conditions
- Comprehensive coverage of real-world driving scenarios

This dataset aims to support research and development in autonomous driving perception systems, particularly for deep learning applications requiring diverse and well-annotated training data.

The dataset is free to [download](https://www.kaggle.com/datasets/ghosnp/carla-4scenes), and the collecting tool is [open source](https://github.com/Kazawaryu/CARLA_ADA).

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.html path="assets/img/blog/other/0000017576.png" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    More details in https://www.kaggle.com/datasets/ghosnp/carla-4scenes
</div>