<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://jonaruthardt.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://jonaruthardt.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-02-19T05:33:38+00:00</updated><id>https://jonaruthardt.github.io/feed.xml</id><title type="html">blank</title><subtitle>Academic website of Zexuan Jia. </subtitle><entry><title type="html">DeepSeek Application Integrations</title><link href="https://jonaruthardt.github.io/blog/2025/ds/" rel="alternate" type="text/html" title="DeepSeek Application Integrations"/><published>2025-02-02T15:12:00+00:00</published><updated>2025-02-02T15:12:00+00:00</updated><id>https://jonaruthardt.github.io/blog/2025/ds</id><content type="html" xml:base="https://jonaruthardt.github.io/blog/2025/ds/"><![CDATA[<p>&lt;/br&gt; &lt;/br&gt;</p> <h3 id="applications">Applications</h3> <table> <tr> <td> <img src="https://avatars.githubusercontent.com/u/171659527?s=400&amp;u=39906ab3b6e2066f83046096a66a77fb3f8bb836&amp;v=4" alt="Icon" width="64" height="auto"/> </td> <td> <a href="https://github.com/quantalogic/quantalogic">Quantalogic</a> </td> <td> QuantaLogic is a ReAct (Reasoning &amp; Action) framework for building advanced AI agents. </td> </tr> <tr> <td> <img src="https://github.com/deepseek-ai/awesome-deepseek-integration/assets/13600976/224d547a-6fbc-47c8-859f-aa14813e2b0f" alt="Icon" width="64" height="auto"/> </td> <td> <a href="docs/chatbox/README.md">Chatbox</a> </td> <td> Chatbox is a desktop client for multiple cutting-edge LLM models, available on Windows, Mac and Linux. </td> </tr> <tr> <td> <img src="https://github.com/deepseek-ai/awesome-deepseek-integration/assets/59196087/bb65404c-f867-42d8-ae2b-281fe953ab54" alt="Icon" width="64" height="auto"/> </td> <td> <a href="docs/chatgpt_next_web/README.md"> ChatGPT-Next-Web </a> </td> <td> ChatGPT Next Web is a cross-platform ChatGPT web UI, with GPT3, GPT4 &amp; Gemini Pro support. </td> </tr> <tr> <td> <img src="./docs/Coco AI/assets/favicon.png" alt="Icon" width="64" height="auto"/> </td> <td> <a href="docs/Coco AI/README.md">Coco AI</a></td> <td> <a href="https://coco.rs">Coco AI</a> is a fully open-source, cross-platform unified search and productivity tool that connects and searches across various data sources, including applications, files, Google Drive, Notion, Yuque, Hugo, and more, both local and cloud-based. By integrating with large models like DeepSeek, Coco AI enables intelligent personal knowledge management, emphasizing privacy and supporting private deployment, helping users quickly and intelligently access their information. </td> </tr> <tr> <td> <img src="./docs/liubai/assets/liubai-logo.png" alt="Icon" width="64" height="auto"/> </td> <td> <a href="docs/liubai/README.md">Liubai</a> </td> <td> Liubai allows DeepSeek to have arms and legs to manipulate your notes, tasks, calendars, and to-do lists just on WeChat! </td> </tr> <tr> <td> <img src="https://github.com/deepseek-ai/awesome-deepseek-integration/assets/59196087/1ac9791b-87f7-41d9-9282-a70698344e1d" alt="Icon" width="64" height="auto"/> </td> <td> <a href="docs/pal/README.md"> Pal - AI Chat Client<br/>(iOS, ipadOS) </a> </td> <td> Pal is a customized chat playground on iOS. </td> </tr> <tr> <td> <img src="https://www.librechat.ai/librechat.svg" alt="LibreChat" width="64" height="auto"/> </td> <td> <a href="https://www.librechat.ai/docs/configuration/librechat_yaml/ai_endpoints/deepseek">LibreChat</a> </td> <td> LibreChat is a customizable open-source app that seamlessly integrates DeepSeek for enhanced AI interactions. </td> </tr> <tr> <td> <img src="https://raw.githubusercontent.com/longevity-genie/chat-ui/11c6647c83f9d2de21180b552474ac5ffcf53980/static/geneticsgenie/icon-128x128.png" alt="Icon" width="64" height="auto"/> </td> <td> <a href="https://github.com/longevity-genie/just-chat">Just-Chat</a> </td> <td> Make your LLM agent and chat with it simple and fast!</td> </tr> <tr> <td> <img src="https://www.papersgpt.com/images/logo/favicon.ico" alt="PapersGPT" width="64" height="auto"/> </td> <td> <a href="https://github.com/papersgpt/papersgpt-for-zotero">PapersGPT</a> </td> <td> PapersGPT is a Zotero plugin that seamlessly with DeepSeek and other multiple AI models for quickly reading papers in Zotero. </td> </tr> <tr> <td> <img src="https://raw.githubusercontent.com/rss-translator/RSS-Translator/main/core/static/favicon.ico" alt="Icon" width="64" height="auto"/> </td> <td> <a href="docs/rss_translator/README.md"> RSS Translator </a> </td> <td> Translate RSS feeds into your language! </td> </tr> <tr> <td> <img src="https://raw.githubusercontent.com/ysnows/enconvo_media/main/logo.png" alt="Icon" width="64" height="auto"/> </td> <td> <a href="docs/enconvo/README.md"> Enconvo </a> </td> <td> Enconvo is the Launcher of the AI era, the entry point for all AI functions, and a thoughtful intelligent assistant.</td> </tr> <tr> <td><img src="https://github.com/kangfenmao/cherry-studio/blob/main/src/renderer/src/assets/images/logo.png?raw=true" alt="Icon" width="64" height="auto" style="border-radius: 10px"/></td> <td><a href="docs/cherrystudio/README.md">Cherry Studio</a></td> <td>A powerful desktop AI assistant for producer</td> </tr> <tr> <td> <img src="https://tomemo.top/images/logo.png" alt="Icon" width="64" height="auto"/> </td> <td> <a href="docs/tomemo/README.md"> ToMemo (iOS, ipadOS) </a> </td> <td> A phrasebook + clipboard history + keyboard iOS app with integrated AI macromodeling for quick output use in the keyboard.</td> </tr> <tr> <td> <img src="https://raw.githubusercontent.com/buxuku/video-subtitle-master/refs/heads/main/resources/icon.png" alt="Icon" width="64" height="auto"/> </td> <td> <a href="https://github.com/buxuku/video-subtitle-master">Video Subtitle Master</a></td> <td> Batch generate subtitles for videos, with the ability to translate subtitles into other languages. This is a client-side tool that supports both Mac and Windows platforms and integrates with multiple translation services such as Baidu, Volcengine, DeepLx, OpenAI, DeepSeek, and Ollama.</td> </tr> <tr> <td> <img src="https://github.com/UnknownEnergy/chatgpt-api/blob/master/dist/assets/chatworm-72x72.png" alt="Icon" width="64" height="auto"/> </td> <td> <a href="https://github.com/UnknownEnergy/chatgpt-api/blob/master/README.md">Chatworm</a> </td> <td> Chatworm is a webapp for multiple cutting-edge LLM models, open-source and also available on Android. </td> </tr> <tr> <td> <img src="https://raw.githubusercontent.com/tisfeng/ImageBed/main/uPic/icon_512x512@2x.png" alt="Icon" width="64" height="auto"/> </td> <td> <a href="https://github.com/tisfeng/Easydict">Easydict</a></td> <td> Easydict is a concise and easy-to-use translation dictionary macOS App that allows you to easily and elegantly look up words or translate text. Supports calling large language model APIs for translation.</td> </tr> <tr> <td> <img src="https://www.raycast.com/favicon-production.png" alt="Icon" width="64" height="auto"/> </td> <td> <a href="docs/raycast/README.md">Raycast</a></td> <td> <a href="https://raycast.com/?via=ViGeng">Raycast</a> is a productivity tool for macOS that lets you control your tools with a few keystrokes. It supports various extensions including DeepSeek AI.</td> </tr> &lt;/tr&gt; <td> <img src="https://niceprompt.app/favicon.ico" alt="Icon" width="64" height="auto"/> </td> <td> <a href="https://niceprompt.app">Nice Prompt</a></td> <td> <a href="https://niceprompt.app">Nice Prompt</a> Organize, share and use your prompts in your code editor, with Cursor and VSCode„ÄÇ</td> &lt;/tr&gt; <tr> <td> <img src="https://avatars.githubusercontent.com/u/193405629?s=200&amp;v=4" alt="PHP Client" width="64" height="auto"/> </td> <td> <a href="https://github.com/deepseek-php/deepseek-php-client/blob/master/README.md">PHP Client</a> </td> <td> Deepseek PHP Client is a robust and community-driven PHP client library for seamless integration with the Deepseek API. </td> </tr> <tr> <tr> <td> <img src="https://github.com/tornikegomareli/DeepSwiftSeek/blob/main/logo.webp" alt="DeepSwiftSeek Logo" width="64" height="auto"/> </td> <td> <a href="https://github.com/tornikegomareli/DeepSwiftSeek/blob/main/README.md">DeepSwiftSeek</a> </td> <td> DeepSwiftSeek is a lightweight yet powerful Swift client library, pretty good integration with the DeepSeek API. It provides easy-to-use Swift concurrency for chat, streaming, FIM (Fill-in-the-Middle) completions, and more. </td> </tr> <td> <img src="https://avatars.githubusercontent.com/u/958072?s=200&amp;v=4" alt="Laravel Integration" width="64" height="auto"/> </td> <td> <a href="https://github.com/deepseek-php/deepseek-laravel/blob/master/README.md">Laravel Integration</a> </td> <td> Laravel wrapper for Deepseek PHP client, to seamless deepseek API integration with laravel applications.</td> </tr> <tr> <td> <img src="./docs/zotero/assets/zotero-icon.png" alt="Icon" width="64" height="auto"/> </td> <td> <a href="docs/zotero/README_cn.md">Zotero</a></td> <td> <a href="https://www.zotero.org">Zotero</a> is a free, easy-to-use tool to help you collect, organize, annotate, cite, and share research.</td> </tr> <tr> <td> <img src="https://b3log.org/images/brand/siyuan-128.png" alt="Icon" width="64" height="auto"/> </td> <td> <a href="docs/SiYuan/README.md">SiYuan</a> </td> <td> SiYuan is a privacy-first personal knowledge management system that supports complete offline usage, as well as end-to-end encrypted data sync.</td> </tr> <tr> <td> <img src="https://github.com/ArvinLovegood/go-stock/raw/master/build/appicon.png" alt="Icon" width="64" height="auto"/> </td> <td> <a href="https://github.com/ArvinLovegood/go-stock/blob/master/README.md">go-stock</a> </td> <td>go-stock is a Chinese stock data viewer built by Wails with NativeUI and powered by LLM.</td> </tr> <tr> <td> <img src="https://avatars.githubusercontent.com/u/102771702?s=200&amp;v=4" alt="Wordware" width="64" height="auto"/> </td> <td> <a href="docs/wordware/README.md">Wordware</a> </td> <td><a href="https://www.wordware.ai/">Wordware</a> is a toolkit that enables anyone to build, iterate, and deploy their AI stack with just natural language.</td> </tr> <tr> <td> <img src="https://framerusercontent.com/images/xRJ6vNo9mUYeVNxt0KITXCXEuSk.png" alt="Icon" width="64" height="auto"/> </td> <td> <a href="https://github.com/langgenius/dify/">Dify</a> </td> <td> <a href="https://dify.ai/">Dify</a> is an LLM application development platform that supports DeepSeek models for creating assistants, workflows, text generators, and more. </td> </tr> <tr> <td> <img src="https://raw.githubusercontent.com/enricoros/big-AGI/refs/heads/v2-dev/public/favicon.ico" alt="Big-AGI" width="64" height="auto"/> </td> <td> <a href="https://github.com/enricoros/big-AGI/blob/v2-dev/README.md">Big-AGI</a> </td> <td><a href="https://big-agi.com/">Big-AGI</a> is a groundbreaking AI suite designed to democratize access to advanced artificial intelligence for everyone.</td> </tr> <tr> <td> <img src="https://github.com/LiberSonora/LiberSonora/blob/main/assets/avatar.jpeg?raw=true" alt="Icon" width="64" height="auto"/> </td> <td> <a href="https://github.com/LiberSonora/LiberSonora/blob/main/README_en.md">LiberSonora</a> </td> <td> LiberSonora, meaning "Voice of Freedom", is an AI-powered, robust, open-source audiobook toolkit that includes features like intelligent subtitle extraction, AI title generation, multilingual translation, with support for GPU acceleration and batch offline processing.</td> </tr> <tr> <td> <img src="https://raw.githubusercontent.com/ripperhe/Bob/master/docs/_media/icon_128.png" alt="Icon" width="64" height="auto"/> </td> <td> <a href="https://bobtranslate.com/">Bob</a></td> <td> <a href="https://bobtranslate.com/">Bob</a> is a macOS translation &amp; OCR tool ready to use in any app ‚Äî right out of the box!</td> </tr> <tr> <td> <img src="https://agenticflow.ai/favicon.ico" alt="Icon" width="64" height="auto"/> </td> <td> <a href="https://agenticflow.ai/">AgenticFlow</a> </td> <td> <a href="https://agenticflow.ai/">AgenticFlow</a> is a no-code platform where marketers build agentic AI workflows for go-to-market automation, powered by hundreds of everyday apps as tools for your AI agents.</td> </tr> <tr> <td> <img src="https://github.com/ZGGSONG/STranslate/raw/main/img/favicon.svg" alt="Icon" width="64" height="auto"/> </td> <td> <a href="https://stranslate.zggsong.com/en/">STranslate</a></td> <td> <a href="https://stranslate.zggsong.com/en/">STranslate</a>ÔºàWindowsÔºâ is a ready-to-go translation ocr tool developed by WPF </td> </tr> <tr> <td> <img src="https://github.com/user-attachments/assets/5e16beb0-993e-47bf-807e-7c8804b313a2" alt="Asp Client" width="64" height="auto"/> </td> <td> <a href="https://github.com/Anwar-alhitar/Deepseek.Asp.Client/blob/master/README.md">ASP Client</a> </td> <td><a href="https://github.com/Anwar-alhitar/Deepseek.Asp.Client/blob/master/README.md">Deepseek.ASPClient</a> is a lightweight ASP.NET wrapper for the Deepseek AI API, designed to simplify AI-driven text processing in .NET applications.. </td> </tr> <tr> <td> <img src="https://www.gptaiflow.tech/logo.png" alt="gpt-ai-flow-logo" width="64" height="auto"/> </td> <td> <a href="https://www.gptaiflow.tech/docs/product/api-keys-setup#setup-deepseek-api-keys">GPT AI Flow</a></td> <td> The ultimate productivity weapon built by engineers for efficiency enthusiasts (themselves): <a href="https://www.gptaiflow.tech/">GPT AI Flow</a> <ul> <li>`Shift+Alt+Space` Wake up desktop intelligent hub</li> <li>Local encrypted storage</li> <li>Custom instruction engine</li> <li>On-demand calling without subscription bundling</li> </ul> </td> </tr> <tr> <td> <img src="https://github.com/user-attachments/assets/b09f17a8-936d-4dac-8b24-1682d52c9a3c" alt="Icon" width="64" height="auto"/> </td> <td> <a href="https://github.com/alecm20/story-flicks">Story-Flicks</a></td> <td>With just one sentence, you can quickly generate high-definition story short videos, supporting models such as DeepSeek.</td> </tr> <tr> <td> <img src="https://prompt.16x.engineer/favicon.ico" alt="Icon" width="64" height="auto"/> </td> <td> <a href="docs/16x_prompt/README.md">16x Prompt</a> </td> <td> <a href="https://prompt.16x.engineer/">16x Prompt</a> is an AI coding tool with context management. It helps developers manage source code context and craft prompts for complex coding tasks on existing codebases.</td> </tr> <tr> <td> <img src="https://docs.xark-argo.com/img/logo.png" alt="Icon" width="64" height="auto"/> </td> <td> <a href="https://www.xark-argo.com">argo</a> </td> <td>Locally download and run Ollama and Huggingface models with RAG on Mac/Windows/Linux. Support LLM API too.</td> </tr> <tr> <td> <img src="https://www.petercat.ai/images/favicon.ico" alt="Icon" width="64" height="auto"/> </td> <td> <a href="https://www.petercat.ai">PeterCat</a> </td> <td> A conversational Q&amp;A agent configuration system, self-hosted deployment solutions, and a convenient all-in-one application SDK, allowing you to create intelligent Q&amp;A bots for your GitHub repositories.</td> </tr> <tr> <td> <img src="./docs/ruzhiai_note/assets/play_store_512.png" alt="Icon" width="64" height="auto"/> </td> <td> <a href="docs/ruzhiai_note/README.md">RuZhi AI Notes</a> </td> <td>RuZhi AI Notes is an intelligent knowledge management tool powered by AI, providing one-stop knowledge management and application services including AI search &amp; exploration, AI results to notes conversion, note management &amp; organization, knowledge presentation &amp; sharing. Integrated with DeepSeek model to provide more stable and higher quality outputs.</td> </tr> <tr> <td> <img src="https://cdn.link-ai.tech/doc/CoW%20logo.png" alt="Icon" width="64" height="auto"/> </td> <td> <a href="https://github.com/zhayujie/chatgpt-on-wechat">Chatgpt-on-Wechat</a> </td> <td> Chatgpt-on-Wechat(CoW) is a flexible chatbot framework that supports seamless integration of multiple LLMs, including DeepSeek, OpenAI, Claude, Qwen, and others, into commonly used platforms or office software such as WeChat Official Accounts, WeCom, Feishu, DingTalk, and websites. It also supports a wide range of custom plugins. </td> </tr> <tr> <td> <img src="https://athenalab.ai/assets/favicon/favicon.svg" alt="Icon" width="64" height="auto"/> </td> <td> <a href="https://athenalab.ai/">Athena</a> </td> <td>The world's first autonomous general AI with advanced cognitive architecture and human-like reasoning capabilities, designed to tackle complex real-world challenges.</td> </tr> </table> <h3 id="ai-agent-frameworks">AI Agent frameworks</h3> <table> <tr> <td> <img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/smolagents/mascot_smol.png" alt="Icon" width="64" height="auto"/> </td> <td> <a href="https://github.com/huggingface/smolagents/tree/main"> smolagents </a> </td> <td> The simplest way to build great agents. Agents write python code to call tools and orchestrate other agents. Priority support for open models like DeepSeek-R1! </td> </tr> <tr> <td><img src="https://yomo.run/yomo-logo.png" alt="Icon" width="64" height="auto"/></td> <td><a href="docs/yomo/README.md">YoMo</a></td> <td>Stateful Serverless LLM Function Calling Framework with Strongly-typed Language Support</td> </tr> <tr> <td> <img src="https://raw.githubusercontent.com/superagentxai/superagentX/refs/heads/master/docs/logo/icononly_transparent_nobuffer.png" alt="Icon" width="64" height="auto"/> </td> <td> <a href="docs/superagentx/README.md">SuperAgentX</a> </td> <td>SuperAgentX: A Lightweight Open Source AI Framework Built for Autonomous Multi-Agent Applications with Artificial General Intelligence (AGI) Capabilities.</td> </tr> <tr> <td> <img src="https://panda.fans/_assets/favicons/apple-touch-icon.png" alt="Icon" width="64" height="auto"/> </td> <td> <a href="docs/anda/README.md">Anda</a> </td> <td>A Rust framework for AI agent development, designed to build a highly composable, autonomous, and perpetually memorizing network of AI agents.</td> </tr> <tr> <td> <img src="https://rig.rs/assets/favicon.png" alt="Rig (Rust)" width="64" height="auto"/> </td> <td> <a href="https://rig.rs/)](https://rig.rs/">RIG</a> </td> <td>Build modular and scalable LLM Applications in Rust.</td> </tr> <tr> <td> <img src="https://raw.githubusercontent.com/longevity-genie/chat-ui/11c6647c83f9d2de21180b552474ac5ffcf53980/static/geneticsgenie/icon-128x128.png" alt="Icon" width="64" height="auto"/> </td> <td> <a href="https://github.com/longevity-genie/just-agents">Just-Agents</a> </td> <td>A lightweight, straightforward library for LLM agents - no over-engineering, just simplicity!</td> </tr> <tr> <td> <img src="https://alice.fun/alice-logo.png" alt="Icon" width="64" height="auto"/> </td> <td> <a href="https://github.com/bob-robert-ai/bob/blob/main/alice/readme.md">Alice</a> </td> <td>An autonomous AI agent on ICP, leveraging LLMs like DeepSeek for on-chain decision-making. Alice combines real-time data analysis with a playful personality to manage tokens, mine BOB, and govern ecosystems.</td> </tr> <tr> <td> <img src="https://github.com/Upsonic/Upsonic/blob/9d2e6d43b44defc6744817330625661ca3a2184e/Upsonic%20pp.png" alt="Icon" width="64" height="auto"/> </td> <td> <a href="https://github.com/Upsonic/Upsonic">Upsonic</a> </td> <td>Upsonic offers a cutting-edge enterprise-ready agent framework where you can orchestrate LLM calls, agents, and computer use to complete tasks cost-effectively.</td> </tr> <tr> <td> <img src="https://avatars.githubusercontent.com/u/173022229" alt="Icon" width="64" height="auto"/> </td> <td> <a href="https://github.com/APRO-com">ATTPs</a> </td> <td>A foundational protocol framework for trusted communication between agents. Any agents based on DeepSeek, By integrating with the <a href="https://docs.apro.com/attps">ATTPs</a> SDK, can access features such as agent registration, sending verifiable data, and retrieving verifiable data. So that it can make trusted communication with agents from other platforms. </td> </tr> </table> <h3 id="rag-frameworks">RAG frameworks</h3> <table> <tr> <td> <img src="https://github.com/deepseek-ai/awesome-deepseek-integration/assets/33142505/77093e84-9f7c-4716-9168-bac962fa1372" alt="Icon" width="64" height="auto"/> </td> <td> <a href="docs/ragflow/README.md"> RAGFlow </a> </td> <td> An open-source RAG (Retrieval-Augmented Generation) engine based on deep document understanding. It offers a streamlined RAG workflow for businesses of any scale, combining LLM (Large Language Models) to provide truthful question-answering capabilities, backed by well-founded citations from various complex formatted data. </td> </tr> <tr> <td> <img src="https://raw.githubusercontent.com/pingcap/tidb.ai/main/frontend/app/public/nextra/icon-dark.svg" alt="Icon" width="64" height="auto"/> </td> <td> <a href="docs/autoflow/README.md"> Autoflow </a> </td> <td> <a href="https://github.com/pingcap/autoflow">AutoFlow</a> is an open-source knowledge base tool based on GraphRAG (Graph-based Retrieval-Augmented Generation), built on <a href="https://www.pingcap.com/ai?utm_source=tidb.ai&amp;utm_medium=community">TiDB</a> Vector, LlamaIndex, and DSPy. It provides a Perplexity-like search interface and allows easy integration of AutoFlow's conversational search window into your website by embedding a simple JavaScript snippet. </td> </tr> <tr> <td> <img src="https://assets.zilliz.com/Zilliz_Logo_Mark_White_20230223_041013_86057436cc.png" alt="Icon" width="64" height="auto"/> </td> <td> <a href="https://github.com/zilliztech/deep-searcher"> DeepSearcher </a> </td> <td> DeepSearcher combines powerful LLMs (DeepSeek, OpenAI, etc.) and Vector Databases (Milvus, etc.) to perform search, evaluation, and reasoning based on private data, providing highly accurate answer and comprehensive report. </td> </tr> </table> <h3 id="solana-frameworks">Solana frameworks</h3> <table> <tr> <td> <img src="./docs/solana-agent-kit/assets/sendai-logo.png" alt="Icon" width="128" height="auto"/> </td> <td> <a href="docs/solana-agent-kit/README.md"> Solana Agent Kit </a> </td> <td>An open-source toolkit for connecting AI agents to Solana protocols. Now, any agent, using any Deepseek LLM, can autonomously perform 60+ Solana actions: </td> </tr> </table> <h3 id="synthetic-data-curation">Synthetic data curation</h3> <table> <tr> <td> <img src="https://raw.githubusercontent.com/bespokelabsai/curator/main/docs/Bespoke-Labs-Logomark-Red-crop.png" alt="Icon" width="64" height="auto"/> </td> <td> <a href="docs/curator/README.md"> Curator </a> </td> <td> An open-source tool to curate large scale datasets for post-training LLMs. </td> </tr> <tr> <td> <img src="https://github.com/user-attachments/assets/8455694b-c52e-40ec-847e-adf6a5ac064f" alt="Icon" width="64" height="auto"/> </td> <td> <a href="https://github.com/Kiln-AI/Kiln"> Kiln </a> </td> <td>Generate synthetic datasets and distill R1 models into custom fine-tunes. </td> </tr> </table> <h3 id="im-application-plugins">IM Application Plugins</h3> <table> <tr> <td> <img src="https://github.com/InternLM/HuixiangDou/releases/download/v0.1.0rc1/huixiangdou.jpg" alt="Icon" width="64" height="auto"/> </td> <td> <a href="docs/huixiangdou/README_cn.md">HuixiangDou<br/>(wechat,lark)</a> </td> <td>Domain knowledge assistant in personal WeChat and Feishu, focusing on answering questions.</td> </tr> <tr> <td> <img src="https://github.com/RockChinQ/LangBot/blob/master/res/logo.png?raw=true" alt="Icon" width="64" height="auto"/> </td> <td> <a href="https://github.com/RockChinQ/LangBot">LangBot<br/>ÔºàQQ, Lark, WeComÔºâ</a> </td> <td> LLM-based IM bots framework, supports QQ, Lark, WeCom, and more platforms.</td> </tr> <tr> <td> <img src="https://nonebot.dev/logo.png" alt="Icon" width="64" height="auto"/> </td> <td> <a href="https://github.com/KomoriDev/nonebot-plugin-deepseek">NoneBot<br/>ÔºàQQ, Lark, Discord, TG, etc.Ôºâ</a> </td> <td> Based on NoneBot framework, provide intelligent chat and deep thinking functions, supports QQ, Lark, Discord, TG, and more platforms.</td> </tr> </table> <h3 id="browser-extensions">Browser Extensions</h3> <table> <tr> <td> <img src="https://github.com/deepseek-ai/awesome-deepseek-integration/assets/59196087/9d3f42b8-fcd0-47ab-8b06-1dd0554dd80e" alt="Icon" width="64" height="auto"/> </td> <td> <a href="docs/immersive_translate/README.md"> Immersive Translate </a> </td> <td> Immersive Translate is a bilingual webpage translation plugin. </td> </tr> <tr> <td> <img src="https://lh3.googleusercontent.com/K9i0qJb8phasC5wWf5tU68rhnfvX4swsE0hrhJP-WB3WV7MwE5KpMUIJvHKNHHRE6GKNIvIdTNSWoDMl_NggrmUsaw=s120" alt="Icon" width="64" height="auto"/> </td> <td> <a href="docs/immersive_reading_guide/README.md"> Immersive Reading Guide </a> </td> <td> NO Sidebar!!! Immersive AI web summarization, ask questions... </td> </tr> <tr> <td> <img src="https://github.com/deepseek-ai/awesome-deepseek-integration/assets/59196087/8a301619-a3de-489b-81fd-69aaa7c1c561" alt="Icon" width="64" height="auto"/> </td> <td> <a href="docs/chatgpt_box/README.md"> ChatGPT Box </a> </td> <td> ChatGPT Box is a ChatGPT integration in browser, completely for free. </td> </tr> <tr> <td> <img src="https://github.com/deepseek-ai/awesome-deepseek-integration/assets/59196087/c3d9d100-247a-41cc-97c1-10b01ed25e70" alt="Icon" width="64" height="auto"/> </td> <td> <a href="docs/hcfy/README.md"> hcfy (ÂàíËØçÁøªËØë) </a> </td> <td> hcfy (ÂàíËØçÁøªËØë) is a web browser extension to integrate multiple translation services. </td> </tr> <tr> <td> <img src="https://static.eudic.net/web/trans/en_trans.png" alt="Icon" width="64" height="auto"/> </td> <td> <a href="docs/Lulu Translate/README.md"> Lulu Translate </a> </td> <td> The plugin provides mouse selection translation, paragraph-by-paragraph comparison translation, and PDF document translation functionalities. It can utilize various translation engines, such as DeepSeek AI, Bing, GPT, Google, etc. </td> </tr> <tr> <td> <img src="https://github.com/Bistutu/FluentRead/raw/refs/heads/main/public/icon/192.png" alt="Icon" width="64" height="auto"/> </td> <td> <a href="https://fluent.thinkstu.com/"> FluentRead </a> </td> <td> A revolutionary open-source browser translation plugin that enables everyone to have a native-like reading experience </td> </tr> <tr> <td> <img src="https://www.ncurator.com/_next/image?url=%2Ffavicon.ico&amp;w=96&amp;q=75" alt="Icon" width="64" height="auto"/> </td> <td> <a href="https://www.ncurator.com/"> Ncurator </a> </td> <td> Knowledge Base AI Q&amp;A Assistant - Let AI help you organize and analyze knowledge</td> </tr> <tr> <td> <img src="https://github.com/oinzen/RSSFlow-doc/blob/main/docs/images/en/icon64.png" alt="Icon" width="64" height="auto"/> </td> <td> <a href="https://rssflow.oinchain.com"> RssFlow </a> </td> <td>An intelligent RSS reader browser extension with AI-powered RSS summarization and multi-dimensional feed views. Supports DeepSeek model configuration for enhanced content understanding. </td> </tr> <tr> <td> <img src="https://www.typral.com/_next/image?url=%2Ffavicon.ico&amp;w=96&amp;q=75" alt="Icon" width="64" height="auto"/> </td> <td> <a href="https://www.typral.com/"> Typral </a> </td> <td> Fast AI writer assistant - Let AI help you quickly improve article, paper, text...</td> </tr> <tr> <td> <img src="https://static.trancy.org/assets/trancy_logo.png" alt="Icon" width="64" height="auto"/> </td> <td> <a href="https://www.trancy.org/"> Trancy </a> </td> <td>Immersive bilingual translation, video bilingual subtitles, sentence/word selection translation extension</td> </tr> <tr> <td> <img src="https://ziziyi.com/svg/anything_copilot.svg" alt="Icon" width="64" height="auto"/> </td> <td> <a href="https://github.com/baotlake/anything-copilot"> Anything Copilot </a> </td> <td> Anything Copilot is a browser extension that enables seamless access to mainstream AI tools directly from your sidebar. </td> </tr> </table> <h3 id="vs-code-extensions">VS Code Extensions</h3> <table> <tr> <td> <img src="https://github.com/continuedev/continue/blob/main/docs/static/img/logo.png?raw=true" alt="Icon" width="64" height="auto"/> </td> <td> <a href="docs/continue/README.md"> Continue </a> </td> <td> Continue is an open-source autopilot in IDE. </td> </tr> <tr> <td> <img src="docs/cline/assets/favicon.png?raw=true" alt="Icon" width="64" height="auto"/> </td> <td> <a href="docs/cline/README.md"> Cline </a> </td> <td> Meet Cline, an AI assistant that can use your CLI aNd Editor. </td> </tr> <tr> <td> <img src="https://raw.githubusercontent.com/Sitoi/ai-commit/refs/heads/main/images/logo.png?raw=true" alt="Icon" width="64" height="auto"/> </td> <td> <a href="https://github.com/Sitoi/ai-commit/blob/main/README.md"> AI Commit </a> </td> <td> Use AI to generate git commit messages in VS Code. </td> </tr> </table> <h3 id="visual-studio-extensions">Visual Studio Extensions</h3> <table> <tr> <td> <img src="https://merryyellow.gallerycdn.vsassets.io/extensions/merryyellow/comment2gpt/2.0.5/1739475434185/Microsoft.VisualStudio.Services.Icons.Default" alt="Icon" width="64" height="auto"/> </td> <td> <a href="https://marketplace.visualstudio.com/items?itemName=MerryYellow.Comment2GPT"> Comment2GPT </a> </td> <td> Use OpenAI ChatGPT, Google Gemini, Anthropic Claude, DeepSeek and Ollama through your comments </td> </tr> <tr> <td> <img src="https://merryyellow.gallerycdn.vsassets.io/extensions/merryyellow/codelens2gpt/2.0.5/1739475875714/Microsoft.VisualStudio.Services.Icons.Default" alt="Icon" width="64" height="auto"/> </td> <td> <a href="https://marketplace.visualstudio.com/items?itemName=MerryYellow.CodeLens2GPT"> CodeLens2GPT </a> </td> <td> Use OpenAI ChatGPT, Google Gemini, Anthropic Claude, DeepSeek and Ollama through the CodeLens </td> </tr> <tr> <td> <img src="https://merryyellow.gallerycdn.vsassets.io/extensions/merryyellow/uca-lite/1.4.2/1739392928984/Microsoft.VisualStudio.Services.Icons.Default" alt="Icon" width="64" height="auto"/> </td> <td> <a href="https://marketplace.visualstudio.com/items?itemName=MerryYellow.UCA-Lite"> Unity Code Assist Lite </a> </td> <td> Code assistance for Unity scripts </td> </tr> </table> <h3 id="neovim-extensions">neovim Extensions</h3> <table> <tr> <td> <img src="https://github.com/user-attachments/assets/c316f70a-0a3c-4a32-b148-4df15e609acc" alt="Icon" width="64" height="auto"/> </td> <td> <a href="docs/avante.nvim/README.md"> avante.nvim </a> </td> <td> avante.nvim is an open-source autopilot in IDE. </td> </tr> <tr> <td> <img src="https://github.com/user-attachments/assets/d66dfc62-8e69-4b00-8549-d0158e48e2e0" alt="Icon" width="64" height="auto"/> </td> <td> <a href="docs/llm.nvim/README.md"> llm.nvim </a> </td> <td> A free large language model (LLM) plugin that allows you to interact with LLM in Neovim. Supports any LLM, such as Deepseek, GPT, GLM, Kimi or local LLMs (such as ollama). </td> </tr> <tr> <td> <img src="https://github.com/user-attachments/assets/d66dfc62-8e69-4b00-8549-d0158e48e2e0" alt="Icon" width="64" height="auto"/> </td> <td> <a href="docs/codecompanion.nvim/README.md"> codecompanion.nvim </a> </td> <td> AI-powered coding, seamlessly in Neovim. </td> </tr> <tr> <td> <img src="https://github.com/user-attachments/assets/d66dfc62-8e69-4b00-8549-d0158e48e2e0" alt="Icon" width="64" height="auto"/> </td> <td> <a href="docs/minuet-ai.nvim/README.md"> minuet-ai.nvim </a> </td> <td> Minuet offers code completion as-you-type from popular LLMs including Deepseek, OpenAI, Gemini, Claude, Ollama, Codestral, and more. </td> </tr> </table> <h3 id="jetbrains-extensions">JetBrains Extensions</h3> <table> <tr> <td> <img src="https://plugins.jetbrains.com/files/21520/412905/icon/pluginIcon.svg" alt="Icon" width="64" height="auto"/> </td> <td> <a href="https://ide.unitmesh.cc/quick-start"> AutoDev </a> </td> <td>‚ÄçAutoDev is an open-source AI coding assistant in JetBrain's IDE. </td> </tr> <tr> <td> <img src="https://plugins.jetbrains.com/files/21410/561595/icon/pluginIcon.svg" alt="Icon" width="64" height="auto"/> </td> <td> <a href="https://plugins.jetbrains.com/plugin/21410-onegai-copilot"> Onegai Copilot </a> </td> <td>Onegai Copilot is an AI coding assistant in JetBrain's IDE. </td> </tr> <tr> <td> <img src="https://github.com/continuedev/continue/blob/main/docs/static/img/logo.png?raw=true" alt="Icon" width="64" height="auto"/> </td> <td> <a href="docs/continue/README.md"> Continue </a> </td> <td> Continue is an open-source autopilot in IDE. </td> </tr> <tr> <td> <img src="https://raw.githubusercontent.com/a18792721831/studyplugin/535b9cab69da0f97b42dcaebb00bb0d4ed15c8a6/translate/src/main/resources/META-INF/pluginIcon.svg" alt="Icon" width="64" height="auto"/> </td> <td> <a href="https://plugins.jetbrains.com/plugin/18336-chinese-english-translate">Chinese-English Translate</a> </td> <td> Chinese-English Translate is a multiple translation services in JetBrain's IDE. </td> </tr> <tr> <td> <img src="https://plugins.jetbrains.com/files/24851/659002/icon/pluginIcon.svg" alt="Icon" width="64" height="auto"/> </td> <td> <a href="https://plugins.jetbrains.com/plugin/24851-ai-git-commit">AI Git Commit</a> </td> <td> This plugin uses AI to automatically generate commit messages based on the changes in your code. </td> </tr> </table> <h3 id="discord-bots">Discord Bots</h3> <table> <tr> <td> <img src="https://geneplore.com/img/geneplore_color_logo_circular.png" alt="Icon" width="64" height="auto"/> </td> <td> <a href="docs/Geneplore AI/README.md"> Geneplore AI </a> </td> <td> Geneplore AI runs one of the largest AI Discord bots, now with Deepseek v3 and R1. </td> </tr> </table> <h3 id="native-ai-code-editor">Native AI Code Editor</h3> <table> <tr> <td> <img src="https://global.discourse-cdn.com/flex020/uploads/cursor1/original/2X/a/a4f78589d63edd61a2843306f8e11bad9590f0ca.png" alt="Icon" width="64" height="auto"/> </td> <td> <a href="https://www.cursor.com/"> Cursor </a> </td> <td>‚ÄçThe AI Code Editor based on VS Code</td> </tr> <tr> <td> <img src="https://exafunction.github.io/public/images/windsurf/windsurf-app-icon.svg" alt="Icon" width="64" height="auto"/> </td> <td> <a href="https://codeium.com/windsurf"> WindSurf </a> </td> <td>Another AI Code Editor based on VS Code by Codeium</td> </tr> </table> <h3 id="emacs">Emacs</h3> <table> <tr> <td> <img src="https://upload.wikimedia.org/wikipedia/commons/0/08/EmacsIcon.svg" alt="Icon" width="64" height="auto"/> </td> <td> <a href="https://github.com/karthink/gptel"> gptel </a> </td> <td>A simple LLM client for Emacs</td> </tr> <tr> <td> <img src="https://upload.wikimedia.org/wikipedia/commons/0/08/EmacsIcon.svg" alt="Icon" width="64" height="auto"/> </td> <td> <a href="https://github.com/milanglacier/minuet-ai.el"> Minuet AI </a> </td> <td>Dance with Intelligence in Your Code üíÉ</td> </tr> </table> <h3 id="security">Security</h3> <table> <tr> <td> <img src="https://github.com/lukehinds/awesome-deepseek-integration/blob/codegate/docs/codegate/assets/codegate.png" alt="Icon" width="64" height="auto"/> </td> <td> <a href="https://github.com/stacklok/codegate/"> CodeGate </a> </td> <td> CodeGate: secure AI code generation</td> </tr> </table> <h3 id="others">Others</h3> <table> <tr> <td style="font-size: 64px">ü§ñ</td> <td> <a href="https://github.com/wangrongding/wechat-bot/blob/main/README.md"> Wechat-Bot </a></td> <td> A wechat robot based on WeChaty combined with DeepSeek and other Ai services. </td> </tr> <tr> <td style="font-size: 64px">&#128032;</td> <td> <a href="https://github.com/lunary-ai/abso/blob/main/README.md"> Abso </a></td> <td> TypeScript SDK to interact with any LLM provider using the OpenAI format. </td> </tr> <tr> <td> <img src="https://i.imgur.com/IsQYInJ.png" alt="Icon" width="64" height="auto"/> </td> <td> <a href="https://github.com/djcopley/ShellOracle/"> ShellOracle </a> </td> <td> A terminal utility for intelligent shell command generation. </td> </tr> <tr> <td> <img src="https://avatars.githubusercontent.com/u/178783630?s=200&amp;v=4" alt="Icon" width="64" height="auto"/> </td> <td> <a href="https://github.com/bolna-ai/bolna/"> Bolna </a> </td> <td> Use DeepSeek as the LLM for conversational voice AI agents</td> </tr> <tr> <td> <img src="https://github.com/deepseek-ai/awesome-deepseek-integration/assets/59196087/c1e47b01-1766-4f7e-bfe6-ab3cb3991c30" alt="Icon" width="64" height="auto"/> </td> <td> <a href="https://github.com/deepseek-ai/awesome-deepseek-integration/tree/main/docs/siri_deepseek_shortcut"> siri_deepseek_shortcut </a> </td> <td> Siri equiped with the DeepSeek API </td> </tr> <tr> <td> <img src="https://github.com/n8n-io/n8n/blob/master/assets/n8n-logo.png?raw=true" alt="Icon" width="64" height="auto"/> </td> <td> <a href="https://github.com/rubickecho/n8n-deepseek"> n8n-nodes-deepseek </a> </td> <td> An N8N community node that supports direct integration with the DeepSeek API into workflows. </td> </tr> <tr> <td> <img src="https://framerusercontent.com/images/TSKshn2UFdTyvUi85EDMIXrXgs.png?scale-down-to=512" alt="Icon" width="64" height="auto"/> </td> <td> <a href="https://github.com/Portkey-AI/gateway"> Portkey AI </a> </td> <td> Portkey is a unified API for interacting with over 1600+ LLM models, offering advanced tools for control, visibility, and security in your DeepSeek apps. Python &amp; Node SDK available. </td> </tr> <tr> <td> <img src="https://framerusercontent.com/images/8rF2JOaZ8l9AvM4H6ezliw44aI.png" alt="Icon" width="64" height="auto"/> </td> <td> <a href="https://github.com/BerriAI/litellm"> LiteLLM </a> </td> <td> Python SDK, Proxy Server (LLM Gateway) to call 100+ LLM APIs in OpenAI format. Supports DeepSeek AI with cost tracking as well. </td> </tr> <tr> <td> <img src="https://i.postimg.cc/k5Z4YWjt/Screenshot-2025-01-23-at-6-08-01-PM.png" alt="Icon" width="64" height="auto"/> </td> <td> <a href="https://github.com/mem0ai/mem0"> Mem0 </a> </td> <td> Mem0 enhances AI assistants with an intelligent memory layer, enabling personalized interactions and continuous learning over time. </td> </tr> <tr> <td> <img src="https://www.promptfoo.dev/img/logo-panda.svg" alt="Icon" width="64" height="auto"/> </td> <td> <a href="docs/promptfoo/README.md"> promptfoo </a> </td> <td> Test and evaluate LLM prompts, including DeepSeek models. Compare different LLM providers, catch regressions, and evaluate responses. </td> </tr> <tr> <td> </td> <td> <a href="https://github.com/AndersonBY/deepseek-tokenizer"> deepseek-tokenizer </a> </td> <td> An efficient and lightweight tokenization library for DeepSeek models, relying solely on the `tokenizers` library without heavy dependencies like `transformers`. </td> </tr> <tr> <td> <img src="https://langfuse.com/icon.svg" alt="Icon" width="64" height="auto"/> </td> <td> <a href="https://langfuse.com/docs/integrations/deepseek"> Langfuse </a> </td> <td> Open-source LLM observability platform that helps teams collaboratively debug, analyze, and iterate on their DeepSeek applications. </td> </tr> <tr> <td> CR </td> <td> <a href="https://github.com/hustcer/deepseek-review"> deepseek-review </a> </td> <td> üöÄ Sharpen Your Code, Ship with Confidence ‚Äì Elevate Your Workflow with Deepseek Code Review üöÄ </td> </tr> <tr> <td> <img src="http://gptlocalhost.com/wp-content/uploads/2025/01/icon_1024.png" alt="Icon" width="64" height="auto"/> </td> <td> <a href="https://youtu.be/T1my2gqi-7Q"> GPTLocalost </a> </td> <td> Use DeepSeek-R1 in Microsoft Word Locally. No inference costs. </td> </tr> <tr> <td> <img src="https://github.com/suqicloud/wp-ai-chat/raw/main/ic_logo.png" alt="Icon" width="64" height="auto"/> </td> <td> <a href="https://github.com/suqicloud/wp-ai-chat"> WordPress aiÂä©Êâã </a> </td> <td> Docking Deepseek api for WordPress site ai conversation assistant, post generation, post summary plugin. </td> </tr> </table> <h3 id="star-history">Star History</h3> <p><a href="https://star-history.com/#deepseek-ai/awesome-deepseek-integration&amp;Date"><img src="https://api.star-history.com/svg?repos=deepseek-ai/awesome-deepseek-integration&amp;type=Date" alt="Star History Chart"/></a></p>]]></content><author><name></name></author><category term="extracurricular"/><category term="math"/><summary type="html"><![CDATA[Copy from deepseek-ai]]></summary></entry><entry><title type="html">Self-Study Note - Probabilistic Robotics</title><link href="https://jonaruthardt.github.io/blog/2024/pr-1/" rel="alternate" type="text/html" title="Self-Study Note - Probabilistic Robotics"/><published>2024-12-16T15:12:00+00:00</published><updated>2024-12-16T15:12:00+00:00</updated><id>https://jonaruthardt.github.io/blog/2024/pr-1</id><content type="html" xml:base="https://jonaruthardt.github.io/blog/2024/pr-1/"><![CDATA[<blockquote> <p>The following are my self-study notes for the PhD preparatory course, Probabilistic Robotics. This content is intended solely for personal review and to motivate myself. Please email me at <a href="mailto:12011126@mail.sustech.edu.cn">12011126@mail.sustech.edu.cn</a> to report any issue, and the original course metarials are at <a href="https://mitpress.mit.edu/9780262201629/probabilistic-robotics/">https://mitpress.mit.edu/9780262201629/probabilistic-robotics/</a>. As I own the physical book, translated into Simplified Chinese, I would write the following contents in the same language but not English, in order to prevent using wrong academic expressions.</p> </blockquote>]]></content><author><name></name></author><category term="note"/><category term="math"/><summary type="html"><![CDATA[My PhD preparatory course]]></summary></entry><entry><title type="html">Release of a multimodal autonomous driving dataset in a simulation environment</title><link href="https://jonaruthardt.github.io/blog/2024/C4S/" rel="alternate" type="text/html" title="Release of a multimodal autonomous driving dataset in a simulation environment"/><published>2024-09-01T15:12:00+00:00</published><updated>2024-09-01T15:12:00+00:00</updated><id>https://jonaruthardt.github.io/blog/2024/C4S</id><content type="html" xml:base="https://jonaruthardt.github.io/blog/2024/C4S/"><![CDATA[<p>The dataset is free to <strong><a href="https://www.kaggle.com/datasets/ghosnp/carla-4scenes">download</a></strong>, and the collecting tool is <strong><a href="https://github.com/Kazawaryu/CARLA_ADA">open source</a></strong>.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/blog/other/0000017576-480.webp 480w, /assets/img/blog/other/0000017576-800.webp 800w, /assets/img/blog/other/0000017576-1400.webp 1400w, " sizes="95vw" type="image/webp"/> <img src="/assets/img/blog/other/0000017576.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> More details in https://www.kaggle.com/datasets/ghosnp/carla-4scenes </div> <p>The CARLA-ADA Dataset is a comprehensive multimodal autonomous driving dataset collected using our custom data acquisition tool in the CARLA simulator. The dataset encompasses diverse driving scenarios across urban, rural, highway, and suburban environments, providing a rich variety of real-world driving situations.</p> <p>The dataset features synchronized image and 3D LiDAR point cloud data, capturing five distinct object classes: cars, trucks, pedestrians, bicycles, and buses. With a total size of 35GB, this dataset offers high-quality annotated data suitable for various autonomous driving perception tasks, including object detection, semantic segmentation, and multi-modal fusion research.</p> <p>Key Features:</p> <ul> <li>Multi-environment data collection: urban, rural, highway, and suburban scenes</li> <li>Multi-modality: camera images and LiDAR point clouds</li> <li>Five object classes with careful annotations</li> <li>Diverse weather and lighting conditions</li> <li>Comprehensive coverage of real-world driving scenarios</li> </ul> <p>This dataset aims to support research and development in autonomous driving perception systems, particularly for deep learning applications requiring diverse and well-annotated training data.</p>]]></content><author><name></name></author><category term="code"/><category term="AD"/><category term="dataset"/><summary type="html"><![CDATA[Collected by CARLA-ADA from CARLA 0.9.15]]></summary></entry><entry><title type="html">3D Traffic Vulnerable Group Detection in Simulation-driven Autonomous Driving</title><link href="https://jonaruthardt.github.io/blog/2023/Sim2det3D/" rel="alternate" type="text/html" title="3D Traffic Vulnerable Group Detection in Simulation-driven Autonomous Driving"/><published>2023-10-08T15:12:00+00:00</published><updated>2023-10-08T15:12:00+00:00</updated><id>https://jonaruthardt.github.io/blog/2023/Sim2det3D</id><content type="html" xml:base="https://jonaruthardt.github.io/blog/2023/Sim2det3D/"><![CDATA[<h1 id="introduction">Introduction</h1> <p>Autonomous driving is one of the most exciting topics in the fields of machine learning and deep learning. In recent years, the technology behind autonomous driving has advanced rapidly in both academia and industry. The various aspects of autonomous driving can be divided into three main modules: perception, prediction, and decision-making. Due to the data-driven nature of deep learning models, effective algorithms require high-quality data sets. If these high standards are not met, the desired outcomes are unlikely to be achieved. Currently, it is acknowledged that in the decision-making module, training on 1 million kilometers of data can lead to better results. However, no similar benchmark exists for the perception module.</p> <p>Previous 3D Lidar detection algorithms often overlooked vulnerable traffic groups, such as pedestrians and cyclists. We aim to propose a straightforward strategy or framework that maximizes the utility of unit data frames within enhanced datasets, thereby improving the algorithm‚Äôs detection of vulnerable traffic groups.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/blog/sim2det/framework-480.webp 480w, /assets/img/blog/sim2det/framework-800.webp 800w, /assets/img/blog/sim2det/framework-1400.webp 1400w, " sizes="95vw" type="image/webp"/> <img src="/assets/img/blog/sim2det/framework.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> The simple main pipeline of this project </div> <p>Unfortunately, Lidar sensors are expensive, making them unaffordable for our project team. Furthermore, collecting and annotating Lidar data poses significant challenges. Compared to traditional data or image data for autonomous driving, Lidar data is often ‚Äútoo sparse, abstract in description, and difficult to visualize.‚Äù This is especially true for identifying traffic-disadvantaged groups, as labeling them based on real data is particularly challenging.</p> <p>To address these issues, our project employs a simulation environment for data collection and preparation. We have developed a set of tools to automatically collect and annotate data within this simulation environment, which allows us to directly extract the 3D positions of targets for annotation. Additionally, given the low frequency of vulnerable groups in existing datasets, we constructed simple scenarios in high dimensions to increase the sample size of these groups.</p> <p>In summary, to tackle the challenges posed by the small and unclear samples of vulnerable traffic groups (pedestrians and cyclists) in traditional datasets, our project has built custom collection tools based on a simulation environment. We also proposed a strategic framework to enhance data collection. To verify its effectiveness, we tested our custom dataset across multiple algorithms, observing a significant improvement in the detection of vulnerable traffic groups.</p> <h1 id="related-work">Related Work</h1> <p>CARLA is a powerful open-source simulator designed for autonomous driving research. It can create a virtual urban environment and simulate various sensors, including cameras, LiDAR, and mmWave radar, to provide essential data. Many researchers have developed their self-driving systems within the Carla environment. By utilizing established object detection algorithms such as YOLO and Faster R-CNN to process the data generated by Carla, they can effectively implement object detection in their systems. The same applies to object tracking, where algorithms like GOTURN and Deep SORT can be employed to achieve successful tracking.</p> <p>For this project, we will use the open-source 3D point cloud detection algorithm training framework, OpenPCDet. This framework is currently a popular and lightweight option for point cloud algorithm training and supports a variety of network architectures.</p> <table> <thead> <tr> <th><strong>Model</strong></th> <th><strong>Car@R11</strong></th> <th><strong>Pedestrian@R11</strong></th> <th><strong>Cyclist@R11</strong></th> <th><strong>Dataset</strong></th> </tr> </thead> <tbody> <tr> <td>PointPillar</td> <td>77.28</td> <td>52.29</td> <td>62.68</td> <td>KITTI</td> </tr> <tr> <td>SECOND</td> <td>78.62</td> <td>52.98</td> <td>67.15</td> <td>KITTI</td> </tr> <tr> <td>Voxel R-CNN</td> <td>84.54</td> <td>-</td> <td>-</td> <td>KITTI</td> </tr> <tr> <td>BEVFusion</td> <td>67.75</td> <td>-</td> <td>-</td> <td>nuScenes</td> </tr> <tr> <td>CenterPoint</td> <td>78.08</td> <td>49.74</td> <td>67.22</td> <td>ONCE</td> </tr> <tr> <td>Voxel NeXt</td> <td>30.05</td> <td>-</td> <td>-</td> <td>Argoverse2</td> </tr> </tbody> </table> <p>Among these, we chose the PointPillar model for experiments to verify that our method has improved the detection effect of if groups. Voxel R-CNN was selected for experiments to verify that the traditional vehicle detection effect has also been improved.</p> <h1 id="methodology">Methodology</h1> <h2 id="co-simulation">Co-simulation</h2> <p>This section primarily focuses on creating the simulation scene. In the Carla map, there are numerous static vehicles that are integral to the map design and are not generated through program control. Consequently, their 3D positions do not appear in memory and cannot be annotated. During the training and verification phases, the model may detect these static vehicles but might misclassify them due to the lack of annotations.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/blog/sim2det/ue41-480.webp 480w, /assets/img/blog/sim2det/ue41-800.webp 800w, /assets/img/blog/sim2det/ue41-1400.webp 1400w, " sizes="95vw" type="image/webp"/> <img src="/assets/img/blog/sim2det/ue41.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/blog/sim2det/ue42-480.webp 480w, /assets/img/blog/sim2det/ue42-800.webp 800w, /assets/img/blog/sim2det/ue42-1400.webp 1400w, " sizes="95vw" type="image/webp"/> <img src="/assets/img/blog/sim2det/ue42.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Operate source code version Carla in the Unreal4 </div> <p>Therefore, we first operate in the source version of Carla and use the Unreal4 toolkit to eliminate static vehicles. After that, we used the Carla-Apollo Bridge to let Apollo take over Carla‚Äôs dynamic scene settings and perform visual operations in DreamViewer.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/blog/sim2det/cosim1-480.webp 480w, /assets/img/blog/sim2det/cosim1-800.webp 800w, /assets/img/blog/sim2det/cosim1-1400.webp 1400w, " sizes="95vw" type="image/webp"/> <img src="/assets/img/blog/sim2det/cosim1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/blog/sim2det/cosim2-480.webp 480w, /assets/img/blog/sim2det/cosim2-800.webp 800w, /assets/img/blog/sim2det/cosim2-1400.webp 1400w, " sizes="95vw" type="image/webp"/> <img src="/assets/img/blog/sim2det/cosim2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Operate source code version Carla in the Unreal4 </div> <h2 id="problem-definition">Problem Definition</h2> <p>Given a 3D point cloud, \(\mathbf{P}=\{p_1,p_2,...,p_n\}\), which represents the set of measured points, \(p_i=(x_i,y_i,z_i)\), and presents a snapshots of the surroundings. For objects, \(\mathbf{O}=\{o_1,o_2,...,o_m\}\), represents the set of all objects in point cloud (vehicle, traffic light, pedestrian, etc.), using KITTI format, where \(o_j=(x_j,y_j,z_j,w_j,h_j,l_j,r_j)\).</p> <p>Use \(S_{keep}\) to measure whether to keep the Lidar data.</p> <p>\(S_{keep} \equiv \mathcal{E} (P) \cdot \mathcal{P}(\rho(O),\tau(O))\) where $\mathcal{E}$ decides whether to keep the entire point cloud, and $\mathcal{P}$ decides whether to keep the collected target data.</p> <p>Use \(S_{value}\) to represent the value of current Lidar data for the trainning model,</p> \[S_{value}\equiv \phi(P, O) \cdot \psi(O)\] <p>where \(\phi(P, O)\) is the perception distance term, used to describe the relationship between the effective perception radius and the farthest perception radius; \(\psi(O)\) is the prediction accuracy term, used to describe the perception How accurate is the prediction of objects within the radius.</p> <h2 id="pedestrian-control-algorithm">Pedestrian Control Algorithm</h2> <p>For pedestrian control in the Co-Simulate link, there is the following algorithm. It controls pedestrian behavior during the time between two timestamps, where $pos$ is the position, $range$ is perception range (only 160 degrees in front of the eyes), $towards$ is the absolute angle of orientation, and $speed$ is the speed of a pedestrian, respectively.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/blog/sim2det/code-480.webp 480w, /assets/img/blog/sim2det/code-800.webp 800w, /assets/img/blog/sim2det/code-1400.webp 1400w, " sizes="95vw" type="image/webp"/> <img src="/assets/img/blog/sim2det/code.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Simple Pedestrian control pesudo code </div> <h2 id="feature-upgrade">Feature Upgrade</h2> <p>The following is the entire process of our improved VFE processing stage.</p> <ul> <li>De-mean encoding \((P, M, 4)\xrightarrow{}(P, M, 3)\) for each point in Pillar</li> <li>Decentralize the effective points in each Pillar \((P, M, 4)\xrightarrow{} (P, M, 2)\)</li> <li>Mask merge coding: Combine the original \((P, M, 4)\) with the above two codes cat to get the vector of \((P, M, 9)\). There are two points to note here: <ul> <li>Only valid points (\(n\) points per pillar) are operated in each Pillar. If the number of valid points is insufficient, zero will be added, if there are too many, random sample will be used;</li> <li>In the code, the 9-dimensional encoding vector is The first 2 dimensions are replaced by decentralized encoded vectors</li> </ul> </li> <li>Convolution kernel pooling: \((P, M, 9)\xrightarrow{}(P, M, 64)\) and \((P, 64)\)</li> <li>Pillarscatter: Go to the 2D feature map of \((X/vsize, Y/vsize)\) and get the feature map of \((64, X/vsize, Y/vsize)\).</li> </ul> <p>The PointPillar model utilizes a method that differs from Voxel in describing point clouds by employing Pillars, which disregards certain information along the Z-axis. During the VFE encoding process, since the model does not take this information into account, it can also omit it during encoding. This approach enhances coding speed and reduces both training and inference times.</p> <h1 id="experiment">Experiment</h1> <p>A total of three data sets were collected, of which A did not use the scenes we built, and B and D used the scenes we built. Each data set consists of 5 subsets, and the number of ‚Äúvehicles (including cyclists) and pedestrians‚Äù in each subset are \((50,25)\), \((75,37)\), \((100,50)\), \((125,62)\) and \((150,75)\).</p> <table> <thead> <tr> <th><strong>Dataset name</strong></th> <th><strong>Total Frames</strong></th> <th><strong>Map</strong></th> <th><strong>Detail</strong></th> </tr> </thead> <tbody> <tr> <td>A</td> <td>987</td> <td>Town05</td> <td>City</td> </tr> <tr> <td>B</td> <td>902</td> <td>Town02</td> <td>Town</td> </tr> <tr> <td>D</td> <td>988</td> <td>Town06</td> <td>Highway</td> </tr> <tr> <td>V</td> <td>375</td> <td>-</td> <td>Random select from A,B, D</td> </tr> </tbody> </table> <p>Then, use datasets A, B, and D to train on PointPillar and Voxel R-CNN, respectively. Use epoch = 160, batch size = 18, dynamically adjust the learning rate, and set Random seed = 114. This results in a total of 6 models. All model training is performed on the server, and the server parameters are as follows.</p> <ul> <li>CPU: Intel(R) Xeon(R) CPU E5-2690 v4 @ 2.60GHz</li> <li>GPU: NVIDIA TITAN V \(\times \ 6\)</li> <li>OS: Ubuntu 22.04.2 LTS</li> <li>MEM: 453 G</li> </ul> <h1 id="results">Results</h1> <p>Via TensorBoard tool, the following is the exported curve of the loss decreasing as the step increases.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/blog/sim2det/loss_pp-480.webp 480w, /assets/img/blog/sim2det/loss_pp-800.webp 800w, /assets/img/blog/sim2det/loss_pp-1400.webp 1400w, " sizes="95vw" type="image/webp"/> <img src="/assets/img/blog/sim2det/loss_pp.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/blog/sim2det/loss_vr-480.webp 480w, /assets/img/blog/sim2det/loss_vr-800.webp 800w, /assets/img/blog/sim2det/loss_vr-1400.webp 1400w, " sizes="95vw" type="image/webp"/> <img src="/assets/img/blog/sim2det/loss_vr.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Training loss curves of Pointpillars (left) and Voxel R-CNN (right). </div> <p>The following are the evaluation results of Pointpillars after training in OpenPCDet. The indicator uses mAP70, that is, mAP above 70 is calculated as correct recognition.</p> <table> <thead> <tr> <th><strong>Dataset</strong></th> <th><strong>Car</strong></th> <th><strong>Truck</strong></th> <th><strong>Van</strong></th> <th><strong>Pedestrian</strong></th> <th><strong>Cyclist</strong></th> </tr> </thead> <tbody> <tr> <td>A</td> <td>53.86</td> <td>68.32</td> <td>52.78</td> <td>38.08</td> <td>45.11</td> </tr> <tr> <td>B</td> <td>60.28</td> <td>71.27</td> <td>54.11</td> <td>40.87</td> <td><strong>56.30</strong></td> </tr> <tr> <td>D</td> <td>64.09</td> <td>68.59</td> <td>71.09</td> <td><strong>48.05</strong></td> <td>52.26</td> </tr> </tbody> </table> <p>Similarly, the result of Voxel-RCNN is shown as the followed.</p> <table> <thead> <tr> <th><strong>Dataset</strong></th> <th><strong>Vehicle</strong></th> </tr> </thead> <tbody> <tr> <td>A</td> <td>8.63</td> </tr> <tr> <td>B</td> <td><strong>64.28</strong></td> </tr> <tr> <td>D</td> <td>63.21</td> </tr> </tbody> </table> <p>Visual display of some data of the model on the test set.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/blog/sim2det/pd1-480.webp 480w, /assets/img/blog/sim2det/pd1-800.webp 800w, /assets/img/blog/sim2det/pd1-1400.webp 1400w, " sizes="95vw" type="image/webp"/> <img src="/assets/img/blog/sim2det/pd1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/blog/sim2det/pd1-1-480.webp 480w, /assets/img/blog/sim2det/pd1-1-800.webp 800w, /assets/img/blog/sim2det/pd1-1-1400.webp 1400w, " sizes="95vw" type="image/webp"/> <img src="/assets/img/blog/sim2det/pd1-1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/blog/sim2det/pd2-480.webp 480w, /assets/img/blog/sim2det/pd2-800.webp 800w, /assets/img/blog/sim2det/pd2-1400.webp 1400w, " sizes="95vw" type="image/webp"/> <img src="/assets/img/blog/sim2det/pd2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/blog/sim2det/pd2-1-480.webp 480w, /assets/img/blog/sim2det/pd2-1-800.webp 800w, /assets/img/blog/sim2det/pd2-1-1400.webp 1400w, " sizes="95vw" type="image/webp"/> <img src="/assets/img/blog/sim2det/pd2-1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/blog/sim2det/pv1-480.webp 480w, /assets/img/blog/sim2det/pv1-800.webp 800w, /assets/img/blog/sim2det/pv1-1400.webp 1400w, " sizes="95vw" type="image/webp"/> <img src="/assets/img/blog/sim2det/pv1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/blog/sim2det/pv1-1-480.webp 480w, /assets/img/blog/sim2det/pv1-1-800.webp 800w, /assets/img/blog/sim2det/pv1-1-1400.webp 1400w, " sizes="95vw" type="image/webp"/> <img src="/assets/img/blog/sim2det/pv1-1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Visualization of different models trained on different data sets under the numbered data frames shown </div> <p>It is not difficult to find that the PointPillar model can basically accurately detect small objects in the distance. Voxel R-CNN has correctly and completely detected all vehicles in this scene, even those with severe occlusion.</p> <h1 id="conclusions">Conclusions</h1> <p>In this prpject, we address the current oversight of vulnerable traffic groups, such as pedestrians and cyclists, in 3D detection algorithms. We propose a project framework utilizing the Carla simulation environment, which encompasses scene construction, data preparation, and model training. We conducted experiments using the PointPillar algorithm and the Voxel R-CNN algorithm within the OpenPCDet framework. The experimental results demonstrate that our approach is more effective, significantly enhancing the 3D detection capabilities for vulnerable traffic groups while also improving performance in general vehicle detection tasks.</p>]]></content><author><name></name></author><category term="course-work"/><category term="AD"/><summary type="html"><![CDATA[Introduces a new joint simulation strategy that combines Carla and Apollo to enhance data quality and improve model performance.]]></summary></entry><entry><title type="html">A Review of 3D Point Cloud Detection Algorithms - from PointNet to VoxelNeXt</title><link href="https://jonaruthardt.github.io/blog/2023/pcd-survey/" rel="alternate" type="text/html" title="A Review of 3D Point Cloud Detection Algorithms - from PointNet to VoxelNeXt"/><published>2023-08-17T15:12:00+00:00</published><updated>2023-08-17T15:12:00+00:00</updated><id>https://jonaruthardt.github.io/blog/2023/pcd-survey</id><content type="html" xml:base="https://jonaruthardt.github.io/blog/2023/pcd-survey/"><![CDATA[<blockquote> <p>This article introduces some common 3D point cloud detection algorithms (as of August 2023). The content comes from personal understanding and may have some problems.</p> </blockquote> <h1 id="1-ÊëòË¶Å">1. ÊëòË¶Å</h1> <p>ËøëÂπ¥Êù•ÔºåÊøÄÂÖâÈõ∑ËææÁÇπ‰∫ëÁõÆÊ†áÊ£ÄÊµãÁÆóÊ≥ïÂú®Ëá™Âä®È©æÈ©∂„ÄÅÊú∫Âô®‰∫∫ÊÑüÁü•Á≠âÈ¢ÜÂüü‰∏≠ÊâÆÊºîÁùÄÈáçË¶ÅËßíËâ≤„ÄÇÊú¨ÁªºËø∞Êó®Âú®ÂõûÈ°æÊøÄÂÖâÈõ∑ËææÁÇπ‰∫ëÁõÆÊ†áÊ£ÄÊµãÁÆóÊ≥ïÁöÑÂèëÂ±ïÂéÜÁ®ãÔºåÈáçÁÇπÂÖ≥Ê≥®‰ªéÁªèÂÖ∏ÁöÑPointNetÁÆóÊ≥ïÂà∞ÊúÄÊñ∞ÁöÑVoxelNextÁÆóÊ≥ïÁöÑÊºîËøõËøáÁ®ã„ÄÇÊàëÂ∞Ü‰ªéÁÆóÊ≥ïÁöÑÂü∫Êú¨ÂéüÁêÜ„ÄÅÊñπÊ≥ï‰ºòÂä£Âäø„ÄÅÂÆûÈ™åÁªìÊûúÁ≠âÊñπÈù¢ÁªºÂêàËØÑËø∞ÂêÑ‰∏™ÁÆóÊ≥ïÔºåÂπ∂ÊèêÂá∫ÂΩìÂâçÁ†îÁ©∂ÁöÑÊåëÊàòÂíåÊú™Êù•ÂèëÂ±ïÊñπÂêë„ÄÇ‰Ωú‰∏∫ÊøÄÂÖâÈõ∑ËææÁÇπ‰∫ëÁõÆÊ†áÊ£ÄÊµãÁÆóÊ≥ïÁöÑÂ≠¶‰π†ÂêØËíô„ÄÇ</p> <h1 id="2-ÂºïË®Ä">2. ÂºïË®Ä</h1> <h2 id="21-ËÉåÊôØ">2.1 ËÉåÊôØ</h2> <p>Ëá™Âä®È©æÈ©∂ÂíåÊú∫Âô®‰∫∫ÊäÄÊúØÁöÑÂø´ÈÄüÂèëÂ±ïÊé®Âä®‰∫ÜÊøÄÂÖâÈõ∑ËææÁÇπ‰∫ëÁõÆÊ†áÊ£ÄÊµãÁÆóÊ≥ïÁöÑÁ†îÁ©∂„ÄÇÊøÄÂÖâÈõ∑ËææÁÇπ‰∫ë‰Ωú‰∏∫‰∏ÄÁßçÈáçË¶ÅÁöÑ‰∏âÁª¥ÊÑüÁü•Êï∞ÊçÆÔºåÂÖ∑ÊúâÈ´òÁ≤æÂ∫¶Âíå‰∏∞ÂØåÁöÑÁ©∫Èó¥‰ø°ÊÅØÔºåÂõ†Ê≠§Ë¢´ÂπøÊ≥õÂ∫îÁî®‰∫éÁõÆÊ†áÊ£ÄÊµã‰ªªÂä°‰∏≠„ÄÇÊÑüÁü•ÁéØËäÇÔºåÂèàÂèØ‰ª•ÁªÜÂàÜ‰∏∫Â§ö‰∏™Ê®°Âùó„ÄÇÂÖ∑‰ΩìÊù•ËÆ≤Ôºå‰ªé Detection, Postion, On-board Map ‰∏â‰∏™ÊñπÈù¢ËÄÉËôë„ÄÇÊú¨Êñá‰∏ªË¶ÅËÄÉËôëÁöÑÊòØÂÖ∂‰∏≠ÁöÑ Detection ÊñπÈù¢„ÄÇËØ•ÁéØËäÇ‰∏ªË¶ÅËÄÉËôëÂ¶Ç‰ΩïÂÆûÊó∂Ê£ÄÊµãÈöúÁ¢çÁâ©„ÄÅÁõÆÊ†áÁâ©Á≠â„ÄÇ</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/blog/pcd-survey/%E5%BC%95%E8%A8%80-480.webp 480w, /assets/img/blog/pcd-survey/%E5%BC%95%E8%A8%80-800.webp 800w, /assets/img/blog/pcd-survey/%E5%BC%95%E8%A8%80-1400.webp 1400w, " sizes="95vw" type="image/webp"/> <img src="/assets/img/blog/pcd-survey/%E5%BC%95%E8%A8%80.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> 3DÊøÄÂÖâÈõ∑ËææÁÇπ‰∫ëÁõÆÊ†áÊ£ÄÊµã </div> <ul> <li>2016Âπ¥ÔºåPointNetÈ¶ñÊ¨°ÊèêÂá∫ÁÇπ‰∫ëÂàÜÂâ≤ÁöÑÂü∫Êú¨ÊÄùË∑Ø„ÄÅÈ™®Âπ≤ÁΩëÁªúÔºå‰ª•‰∏•Ë∞®ËÄåÂÖ®Èù¢ÁöÑÂÆûÈ™åÈ™åËØÅÁÆóÊ≥ïÂêÑ‰∏™ÁéØËäÇÁöÑÊúâÊïàÊÄß„ÄÇ</li> <li>2017Âπ¥ÔºåVoxelNet‰ª• PointNet ‰∏∫Âü∫Á°ÄÔºåÁî® Voxel ÊèèËø∞ÁÇπ‰∫ëÁ©∫Èó¥ÔºåÊèêÂá∫VFEÔºàVoxel Feature EncoderÔºå‰ΩìÁ¥†ÁâπÂæÅÊèêÂèñÂô®ÔºâÔºå‰Ωú‰∏∫ÂæÄÂêéÂá†‰πé‰∏ÄÂàáÁÇπ‰∫ëÁõÆÊ†áÊ£ÄÊµãÁÆóÊ≥ïÁöÑÈ¶ñË¶ÅÁéØËäÇ„ÄÇ</li> <li>2018Âπ¥ÔºåSECOND‰ΩøÁî®ÊîπËøõÁöÑÁ®ÄÁñèÂç∑ÁßØÂíåÊñ∞ÁöÑÊçüÂ§±ÂáΩÊï∞ÔºåÂØπ VoxelNet ËøõË°å‰∫Ü‰∏Ä‰∫õ‰ºòÂåñÂíåÂÆåÂñÑÔºåÈááÁî®ÊîπËâØÁöÑÁ®ÄÁñèÂç∑ÁßØÔºåÊïàÊûúÊîπÂñÑÊòæËëó„ÄÇ</li> <li>2019Âπ¥ÔºåPointPillar Â∞ÜVoxelNet‰∏≠VoxelÊîπ‰∏∫ÈïøÊù°ÂΩ¢ÁöÑPillarÔºåÈááÁî®SECOND‰∏≠ÁöÑÁ®ÄÁñèÂç∑ÁßØÊ†∏ÔºåÂá†‰πé‰∏çÂΩ±ÂìçÊÄßËÉΩÁöÑÊÉÖÂÜµ‰∏ãÊûÅÂ§ßÂú∞ÊèêÂçá‰∫ÜÊÄßËÉΩÔºåÊòØÂ∑•‰∏öÁïåÂ∏∏Áî®ÁöÑÁÆóÊ≥ï‰πã‰∏Ä„ÄÇ</li> <li>2020Âπ¥ÔºåVoxel R-CNNÂü∫‰∫évoxelÁâπÂæÅÔºåËÆæËÆ°‰∫Ü3DÁÇπ‰∫ëÁõÆÊ†áÊ£ÄÊµãÁöÑtwo stageÁΩëÁªúÔºåÊèêÂçá‰∫Ü‰∫õËÆ∏Ê£ÄÊµãÁ≤æÂ∫¶„ÄÇ</li> <li>2021Âπ¥ÔºåCenterPointÁªßÊâø PointPillar ÁÆóÊ≥ïÁöÑPillarÂåñÊÄùË∑ØÔºåÂπ∂ÁªìÂêà2DÁöÑCenterNetÁÆóÊ≥ïÔºåÂºïÂÖ•Ê≥®ÊÑèÂäõÊú∫Âà∂ÔºåÁúãÂà∞‰∫ÜÂú®3DÊ£ÄÊµã‰∏äÈááÂèñ2DÊ£ÄÊµãÁ≠ñÁï•ÁöÑ‰ºòÂäøÊÄßÔºåËøõ‰∏ÄÊ≠•ÊèêÂçátwo stageÁ≥ªÂàóÁÆóÊ≥ïÊÄßËÉΩ„ÄÇ</li> <li>2023Âπ¥ÔºåVoxel NeXtÂõûÂΩíÂà∞ÁÇπ‰∫ëÊï∞ÊçÆÊú¨Ë¥®ÔºåÈááÁî®Á∫ØÁ®ÄÁñèÁöÑÂç∑ÁßØÁΩëÁªúÔºåËß£ÂÜ≥‰∫ÜCenterPoint‰∏≠Ê≥®ÊÑèÂäõÊµ™Ë¥πÁöÑÈÉ®ÂàÜÔºåÂπ∂ÁªìÂêàSegment AnythingÂºÄÂèëÂá∫‰∏ÄÂ•óÂº∫È≤ÅÊ£íÊ£ÄÊµãÁÆóÊ≥ïÈ©±Âä®ÁöÑËá™Âä®Ê†áÊ≥®Á≥ªÁªü„ÄÇ</li> </ul> <p>‰ª•‰∏äÊòØËøëÂπ¥Êù•‰∏Ä‰∫õ‰ª£Ë°®ÊÄßÊØîËæÉÂº∫ÁöÑÁÇπ‰∫ëÁõÆÊ†áÊ£ÄÊµãÁÆóÊ≥ïÁöÑÂèëÂ±ïÂéÜÁ®ã„ÄÇÊú¨ÊñáÂ∞ÜÂØπÂÖ∂‰∏≠PointNetÔºåVoxelNetÔºåCenterPoint ‰ª•Âèä VoxelNeXtÂõõ‰∏™ÁÆóÊ≥ïËøõË°åËØ¶ÁªÜÁöÑ‰ªãÁªçÔºåÂπ∂ÂàÜÊûêÁÆóÊ≥ïÁöÑÂàõÊñ∞ÁÇπÔºå‰ª•Âèä‰∏Ä‰∫õÊÄùËÄÉ„ÄÇ</p> <h2 id="22-ÈóÆÈ¢òÂÆö‰πâ">2.2 ÈóÆÈ¢òÂÆö‰πâ</h2> <p>3DÁõÆÊ†áÊ£ÄÊµãÊòØËá™Âä®È©æÈ©∂ÁöÑ‰∏Ä‰∏™Âü∫Á°ÄÈÉ®ÂàÜÔºå3DÁõÆÊ†áÊ£ÄÊµãÁΩëÁªúÈÄöÂ∏∏ËæìÂÖ•Á®ÄÁñèÁÇπ‰∫ëÔºåËæìÂá∫Áâ©‰Ωì‰∏âÁª¥‰ΩçÁΩÆ‰ª•ÂèäÁ±ªÂà´„ÄÇÁ°¨‰ª∂ËÆæÂ§áÂ∏∏Â∏∏ÈÄâÁî®ÊøÄÂÖâÈõ∑ËææLidar„ÄÇ</p> <p>ÂØπ‰∫éÊï¥‰∏™ÁÇπ‰∫ëÊï∞ÊçÆÂ∏ß$F$ÔºåÂÖ∂ÂÜÖÈÉ®ÊúâÁÇπÈõÜ\(P = \{p_1,p_2,...,p_n\}, p_k=\{x_k,y_k,z_k,I_k\} , p_k \in P\)Ôºà\(I\)Ë°®Á§∫ÁÇπÁöÑÂº∫Â∫¶‰ø°ÊÅØÔºâ„ÄÇÂØπ\(P\)ÊâßË°åÊ£ÄÊµãÁÆóÊ≥ï\(A\)ÔºåËøîÂõûÈ¢ÑÊµãÁõÆÊ†áÈõÜ\(D=\{d_1,d_2,...,d_m\}, d_i = \{x_i,y_i,z_i,h,w,l,rot,lab\}, d_i\in D\)ÔºåÂÖ∂‰∏≠\(x,y,z\)Ë°®Á§∫3DÊ°ÜÁöÑ‰∏≠ÂøÉÁÇπÔºå\(h,w,l\)Ë°®Á§∫3DÊ°ÜÁöÑÈ´ò„ÄÅÂÆΩ„ÄÅÈïøÔºå\(rot\)Ë°®Á§∫Âú®6ËΩ¥ÂùêÊ†áÁ≥ª‰∏ãÁöÑ\(yaw\)ÊóãËΩ¨ËßíÔºå\(lab\)Ë°®Á§∫3DÊ°ÜÁöÑËØ≠‰πâ‰ø°ÊÅØÔºåÂç≥È¢ÑÊµãÁõÆÊ†áÁöÑÁ±ªÂà´„ÄÇ</p> <h2 id="23-ËØÑ‰º∞Ê†áÂáÜ">2.3 ËØÑ‰º∞Ê†áÂáÜ</h2> <h3 id="231-metrics-based-on-average-precision">2.3.1 Metrics based on Average Precision</h3> <p>Ê£ÄÊµãÁÆóÊ≥ïÁöÑËØÑ‰º∞Ôºå‰∏ÄËà¨ÈááÁî® IoU (Inner of Union) ‰Ωú‰∏∫ËØÑ‰ª∑ BBox Âíå Ground-Truth ÁöÑÈáçÂêàÁ®ãÂ∫¶„ÄÇÊï∞Â≠¶Âª∫Ê®°‰∏∫ÔºåÂØπ‰∫éÂêå‰∏Ä‰∏™ÂØπË±°\(O\)ÔºåÂèñÁÆóÊ≥ïÈ¢ÑÊµãÊ°Ü$D$‰∏éÁúüÂÄºÊ°Ü\(G\) (Ground Truth) ÔºåÊåâÂ¶Ç‰∏ãÂÖ¨ÂºèËÆ°ÁÆóÔºö</p> \[IoU = \frac{area(D)\cap area(G)}{area(D)\cup area(G)}\] <p>ÂÆö‰πâ \(IoU&gt;0.5\)‰∏∫ÁúüÈò≥ÊÄß \(TP\) (True Positive)Ôºå\(IoU\le0.5\)‰∏∫ÂÅáÈò≥ÊÄß\(FP\)ÔºàFalse PositiveÔºâÔºõÂÆö‰πâÁúüÂÄºÊú™Ê£ÄÊµãÁöÑ‰∏∫ÂÅáÈò¥ÊÄß$FN$(False Negivate)ÔºåÂÆö‰πâÊ£ÄÊµãÂá∫‰ΩÜÁúüÂÄº‰∏çÂ≠òÂú®ÁöÑ‰∏∫ÁúüÈò¥ÊÄß\(TN\)(True Positive)„ÄÇÊ†πÊçÆ‰ª•‰∏äÂá†‰∏™ÂÆö‰πâÔºåÂèØ‰ª•ËÆ°ÁÆóÂá∫Ê®°ÂûãÊï¥‰ΩìÁöÑÂáÜÁ°ÆÂ∫¶$P$(Precision) ‰∏éÂè¨ÂõûÁéá\(R\)(Recall)ÔºåÂπ∂ÁªòÂà∂Êàê \(P-R\) Êõ≤Á∫ø„ÄÇ</p> \[P=\frac{TP}{FP+FN}\ \ \ R=\frac{TP}{TP+FN}\] <p>ËÆ°ÁÆóÊõ≤Á∫øÁöÑ‰∏ãÁßØÂàÜÈù¢ÁßØ\(AP\)(Average Precision)„ÄÇËøë‰ººÂú∞ÔºåÁî®‰ª•‰∏ãÂÖ¨Âºè‰º∞ËÆ°\(AP\)ÁöÑÂÄºÔºåË°®Á§∫‰∏∫ÂØπ‰∫éÊ≠§Ê¨°ÊµãËØïÁöÑÊï∞ÊçÆÔºåÊ®°ÂûãÊï¥‰ΩìÁöÑÂπ≥ÂùáÂáÜÁ°ÆÂ∫¶„ÄÇÂØπÊâÄÊúâÊµãËØïÊï∞ÊçÆÊ±ÇÂπ≥ÂùáÔºåÊ±ÇÁöÑ\(mAP\)Áî®‰∫éËØÑ‰º∞Êï¥‰∏™Ê®°ÂûãÂú®ÊµãËØïÈõÜ‰∏äÁöÑÊïàÊûú„ÄÇ</p> <p>\(AP = \sum_{k=0}^{k = n - 1}[Recall(k) - Recall(k-1)] \times Precision(k)\) \(mAP = \frac{1}{n} \sum_{k = 1}^{k = n}AP_k\)</p> <p>Ëøõ‰∏ÄÊ≠•Âú∞ÔºåÊõ¥Êîπ\(IoU\)ÁöÑÈòàÂÄºÔºå‰ªé \(0.5\)‰ª•\(0.05\)‰∏∫Âçï‰ΩçÈÄíÂ¢ûËá≥\(0.95\)ÔºåËÆ°ÁÆóÊØè‰∏™ÈòàÂÄº‰∏ãÁöÑ\(mAP\)ÔºåÊõ¥‰∏•Ê†ºÂú∞ËØÑ‰ª∑Ê®°ÂûãÊïàÊûúÔºåÂ∞ÜËØ•ÊåáÊ†áÁß∞‰∏∫$mAP50-95$„ÄÇ ÂØπ‰∫éÁÇπ‰∫ëÊï∞ÊçÆÔºåÁî±‰∫éÂÖ∂Êï∞ÊçÆÁâπÊúâÁöÑÁ®ÄÁñèÊÄßÔºåÈÄöËøáËÄÉËôëÂú∞Âπ≥Êï∞ÊçÆÁÇπÊØîËæÉÁ®ÄÁñèÂíåÁ¶ªÊï£Ôºå‰∏çÂ•Ω‰ΩúÁâπÂæÅÊèêÂèñÔºåÁî±Èù¢‰∏äÁöÑ 2D ‰∏≠ÂøÉË∑ùÁ¶ªËÄå‰∏çÊòØÂü∫‰∫éËÅîÂêàÁöÑ‰∫≤ÂíåÂäõÁöÑ‰∫§ÈõÜÊù•ÂÆö‰πâÂåπÈÖç„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÂ∞ÜÈ¢ÑÊµã‰∏éÂÖ∑ÊúâÊúÄÂ∞è‰∏≠ÂøÉË∑ùÁ¶ª‰∏îËææÂà∞ÁâπÂÆöÈòàÂÄºÁöÑÂú∞Èù¢ÁúüÂÆûÂØπË±°ËøõË°åÂåπÈÖç„ÄÇÂØπ‰∫éÁªôÂÆöÁöÑÂåπÈÖçÈòàÂÄºÔºåÊàë‰ª¨ÈÄöËøáÊï¥ÂêàÂè¨ÂõûÁéá‰∏éÁ≤æÂ∫¶Êõ≤Á∫øÔºàÂè¨ÂõûÁéáÂíåÁ≤æÂ∫¶ &gt; 0.1ÔºâÊù•ËÆ°ÁÆó$AP$„ÄÇÊàë‰ª¨ÊúÄÁªàÂØπ \(\{0.5,1,2,4\}\) Á±≥ÁöÑÂåπÈÖçÈòàÂÄºËøõË°åÂπ≥ÂùáÔºåÂπ∂ËÆ°ÁÆóÂêÑ‰∏™Á±ªÂà´ÁöÑÂπ≥ÂùáÂÄº„ÄÇ</p> <h3 id="232-metrics-based-on-true-positive">2.3.2 Metrics based on True Positive</h3> <p>‰æùÊçÆnuScenesÊèêÂá∫ÁöÑÊ†áÂáÜÔºåÂÆö‰πâ‰∏ÄÁªÑÁúüÈò≥ÊÄß (TP) ÁöÑÊåáÊ†áÔºåÁî®‰∫éÊµãÈáèÂπ≥Áßª„ÄÅÂ∞∫Â∫¶„ÄÅÊñπÂêë„ÄÅÈÄüÂ∫¶ÂíåÂ±ûÊÄßÈîôËØØ„ÄÇÊâÄÊúâ\(TP\)ÊåáÊ†áÈÉΩÊòØÂú®ÂåπÈÖçÊó∂‰ΩøÁî®$2m$‰∏≠ÂøÉË∑ùÁöÑÈòàÂÄºËÆ°ÁÆóÁöÑÔºåÂπ∂‰∏îÂÆÉ‰ª¨ÈÉΩË¢´ËÆæËÆ°‰∏∫Ê≠£Ê†áÈáè„ÄÇ</p> <p>ÊØè‰∏™Á±ªÂà´ÁöÑÂåπÈÖçÂíåËØÑÂàÜÈÉΩÊòØÁã¨Á´ãËøõË°åÁöÑÔºåÊØè‰∏™ÊåáÊ†áÈÉΩÊòØÊØè‰∏™ËææÂà∞ 10% ‰ª•‰∏äÁöÑÂè¨ÂõûÊ∞¥Âπ≥ÁöÑÁ¥ØÁßØÂπ≥ÂùáÂÄºÁöÑÂπ≥ÂùáÂÄº„ÄÇÂ¶ÇÊûúÁâπÂÆöÁ±ªÂà´Êú™ËææÂà∞ 10\% ÁöÑÂè¨ÂõûÁéáÔºåÂàôËØ•Á±ªÂà´ÁöÑÊâÄÊúâ \(TP\) ÈîôËØØÈÉΩÂ∞ÜËÆæÁΩÆ‰∏∫ 1„ÄÇÊàë‰ª¨ÂÆö‰πâ‰ª•‰∏ã \(TP\) ÈîôËØØÔºö</p> <ul> <li>Âπ≥ÂùáÂπ≥ÁßªËØØÂ∑Æ ATE (Average Translation Error)Ôºö‰∫åÁª¥Ê¨ßÂá†ÈáåÂæó‰∏≠ÂøÉË∑ùÁ¶ªÔºà‰ª•Á±≥‰∏∫Âçï‰ΩçÔºâÔºõ</li> <li>Âπ≥ÂùáÂ∞∫Â∫¶ËØØÂ∑Æ ASE (Average Scale Error)ÔºöÂú®ÂØπÈΩê‰∏≠ÂøÉÂíåÊñπÂêëÂêéËÆ°ÁÆó‰∏∫\(1 - IOU\) Ôºõ</li> <li>Âπ≥ÂùáÊñπÂêëËØØÂ∑Æ AOE(Average Orientation Error)ÔºöÈ¢ÑÊµã‰∏éÂú∞Èù¢ÂÆûÂÜµ‰πãÈó¥ÁöÑÊúÄÂ∞èÂÅèËà™ËßíÂ∑ÆÂºÇÔºà‰ª•ÂºßÂ∫¶‰∏∫Âçï‰ΩçÔºâ„ÄÇÂØπ‰∫éÊâÄÊúâÁ±ªÂà´ÔºåÊñπÂêëËØØÂ∑ÆÂùá‰ª• 360 Â∫¶ËøõË°åËØÑ‰º∞ÔºåÈöúÁ¢çÈô§Â§ñÔºåÈöúÁ¢çÁâ©‰ªÖ‰ª• \(180\)Â∫¶ËøõË°åËØÑ‰º∞„ÄÇÂøΩÁï•Èî•‰ΩìÁöÑÊñπÂêëÈîôËØØÔºõ</li> <li>Âπ≥ÂùáÈÄüÂ∫¶ËØØÂ∑Æ AVE (Average Velocity Error)ÔºöÁªùÂØπÈÄüÂ∫¶ËØØÂ∑ÆÔºå‰ª• \(m/s\) ‰∏∫Âçï‰Ωç„ÄÇÈöúÁ¢çÁâ©ÂíåÈî•‰ΩìÁöÑÈÄüÂ∫¶ËØØÂ∑ÆË¢´ÂøΩÁï•Ôºõ</li> <li>Âπ≥ÂùáÂ±ûÊÄßËØØÂ∑Æ AAE (Average Attribute Error)ÔºöËÆ°ÁÆó‰∏∫\(1 - acc\)ÔºåÂÖ∂‰∏≠ $acc$ ÊòØÂ±ûÊÄßÂàÜÁ±ªÁ≤æÂ∫¶„ÄÇÈöúÁ¢çÁâ©ÂíåÈî•‰ΩìÁöÑÂ±ûÊÄßÈîôËØØË¢´ÂøΩÁï•„ÄÇ</li> </ul> <p>‰ª•‰∏ä5‰∏™Ê†áÂáÜ‰∏émAPÂä†ÊùÉÊ±ÇÂíåÔºåÂç≥nuScenesÂÆö‰πâÁöÑNDS (nuScenes Detection Score) Ê†áÂáÜÔºåÂç≥</p> \[\text{NDS} = 1/10[5\text{mAP}+ {\sum}_{\text{mTP}\in\mathbb{TP}} (1-\min(1, \text{mTP}))]\] <p>‰ª•‰∏äÊâÄÊúâËØØÂ∑ÆÈÉΩ &gt;= 0Ôºå‰ΩÜÊòØÔºåÂØπ‰∫éÂπ≥ÁßªËØØÂ∑ÆÂíåÈÄüÂ∫¶ËØØÂ∑ÆÔºåËØØÂ∑ÆÊòØÊó†ÁïåÁöÑÔºåÂπ∂‰∏îÂèØ‰ª•ÊòØ‰ªª‰ΩïÊ≠£ÂÄº„ÄÇÊ≠§Á±ª $TP$ ÊåáÊ†áÊòØÊåâÁ±ªÂÆö‰πâÁöÑÔºåÁÑ∂ÂêéÊàë‰ª¨ÂèñÁ±ªÁöÑÂπ≥ÂùáÂÄºÊù•ËÆ°ÁÆó \(mATE, mASE, mAOE, mAVE,mAAE\)„ÄÇ</p> <h2 id="24-‰ªªÂä°ÈöæÁÇπ">2.4 ‰ªªÂä°ÈöæÁÇπ</h2> <p>Áî±‰∫éÊ∑±Â∫¶Â≠¶‰π†Êï∞ÊçÆÈ©±Âä®ÁöÑÁâπÊÄßÔºåÂ∞±ÁÆóÊ≥ïËÆ≠ÁªÉËÄåË®ÄÔºåÂú®Êï∞ÊçÆËé∑Âèñ‰∏äÔºåÁõ∏ÊØî‰∏éÂÖ∂‰ªñÊï∞ÊçÆÔºå3DÁÇπ‰∫ëÊï∞ÊçÆÈõÜÁöÑÂà∂Â§áÂíåÂ§ÑÁêÜÈùûÂ∏∏Âõ∞Èöæ„ÄÇ</p> <p>ÂØπÊØî‰∫é 2D ÂõæÂÉèÊï∞ÊçÆÔºåÂ§ÑÁêÜÁÇπ‰∫ëÊï∞ÊçÆÂÖ∑Êúâ‰ª•‰∏ãÂá†‰∏™ÈöæÁÇπ„ÄÇÂú®ÂêéÊñá‰∏≠Ôºå‰ºöÂàÜÂà´ÁÆÄË¶ÅÊèêÂà∞Â¶Ç‰ΩïÂÖãÊúç‰ª•‰∏ãÂá†‰∏™Âõ∞Èöæ„ÄÇÊï∞ÊçÆÁÇπÊØîËæÉÁ®ÄÁñèÂíåÁ¶ªÊï£Ôºå‰∏çÂ•Ω‰ΩúÁâπÂæÅÊèêÂèñÔºåÂô™Â£∞‰∏çÂ•ΩÂå∫Âà´ÔºõÂÖ∑ÊúâÊõ¥Â§öËá™Áî±Â∫¶Ôºå‰∏çÂ•ΩÂ§ÑÁêÜÔºàÊõ¥Â§öÁöÑÂ∞∫ÂØ∏ÁßçÁ±ªÔºåÁõ∏ÂØπ‰∫éÂùêÊ†áÂë®ÊúâÂ§ö‰∏™Áª¥Â∫¶ÁöÑÊóãËΩ¨ÔºâÔºõÊï∞ÊçÆÊ†áÊ≥®Âõ∞ÈöæÔºåÊØè‰∏™Ground TruthÔºàÁúüÂÄºÊ°ÜÔºâÈúÄË¶ÅÂÖ´‰∏™ÁÇπ‰ΩçÁöÑÊ†áÊ≥®„ÄÇ</p> <h2 id="25-Â∏∏ËßÅÁöÑÂÖ¨ÂºÄÊï∞ÊçÆÈõÜ">2.5 Â∏∏ËßÅÁöÑÂÖ¨ÂºÄÊï∞ÊçÆÈõÜ</h2> <p>ÈíàÂØπÊï∞ÊçÆËé∑ÂèñÁöÑÂõ∞ÈöæÔºåÂæÄÂæÄÈááÁî®‰∏Ä‰∫õÂ∏∏ËßÅÁöÑÂºÄÊ∫êÁÇπ‰∫ëÊï∞ÊçÆÈõÜËøõË°åËÆ≠ÁªÉ„ÄÇ</p> <ul> <li>KITTI 3DÔºöÂÖ∑Â§á1.5wÂ∏ßÊï∞ÊçÆÔºå8w‰∏™Ê†áÊ≥®ÁöÑÁõÆÊ†áÔºõ</li> <li>nuScenesÔºöÂÖ∑Â§á39wÂ∏ßÈõ∑ËææÔºå140w‰∏™Ê†áÊ≥®ÁõÆÊ†áÔºå23Á±ªÔºõ</li> <li>WaymoÔºöÂÖ∑Â§á200wÂ∏ßÔºå2260w‰∏™Ê†áÊ≥®ÁõÆÊ†áÔºå4Á±ª+23Á±ªÔºõ</li> <li>Argoverse2ÔºöÂÖ∑Â§á1000‰∏™Âú∫ÊôØÔºåÊØèÂ∏ßÂõæÂÉèÂπ≥ÂùáÊúâ75‰∏™ÁõÆÊ†áÁâ©Ôºå30‰∏™Á±ªÂà´Ôºõ</li> <li>Dense: ‰∏çÂêåÂ§©Ê∞î‰∏ã12000‰∏™Ê†∑Êú¨ÂíåÊµìÈõæ‰∏≠ÁöÑ1500‰∏™Ê†∑Êú¨ÔºåÂ∞ëËßÅÁöÑÊûÅÁ´ØÂ§©Ê∞îÊï∞ÊçÆÈõÜÔºõ</li> <li>SUScapeÔºöÂçóÊñπÁßëÊäÄÂ§ßÂ≠¶‰∏éIntelÂÖ¨Âè∏Âêà‰ΩúÔºåÂú®Ê∑±Âú≥ÈááÈõÜÁöÑÊï∞ÊçÆÈõÜÔºåÂÖ∑Êúâ40+Á±ªÂà´ÔºåÊúâÊïàÂπ≥ÂùáÂÆû‰æãÂØÜÂ∫¶‰∏∫nuSceneÁöÑ10ÂÄç„ÄÇ</li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/blog/pcd-survey/nuScene%E8%BD%A6-480.webp 480w, /assets/img/blog/pcd-survey/nuScene%E8%BD%A6-800.webp 800w, /assets/img/blog/pcd-survey/nuScene%E8%BD%A6-1400.webp 1400w, " sizes="95vw" type="image/webp"/> <img src="/assets/img/blog/pcd-survey/nuScene%E8%BD%A6.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> nuScenesÊï∞ÊçÆÈõÜËΩ¶ËæÜ‰º†ÊÑüÂô®ËÆæÁΩÆ </div> <p>Â¶ÇÊûúÊÉ≥Ë¶ÅËá™Â∑±Âà∂Â§áÊï∞ÊçÆÈõÜÁî®Êù•ËÆ≠ÁªÉÊ®°ÂûãÔºåÂæÄÂæÄÈááÁî®‰ª•‰∏ãÁöÑÊñπÊ≥ï„ÄÇ</p> <ul> <li>Ëá™Âà∂ÁúüÂÆûÊï∞ÊçÆÈõÜÔºöÊú∫Âô®‰∫∫ÈááÈõÜÁúüÂÆûÊï∞ÊçÆÔºåÈÄöËøá Segement AnythingÔºåSUSTechPoint Á≠âÂ∑•ÂÖ∑ËæÖÂä©Ê†áÊ≥®Ôºõ</li> <li>‰ªøÁúüÈááÈõÜÊï∞ÊçÆÈõÜÔºöCarla Á≠â‰ªøÁúüÁéØÂ¢ÉÔºåÊï∞ÊçÆÊ†áÊ≥®Êù•Ê∫ê‰∫éÂØπ‰ªøÁúüÁéØÂ¢ÉÁúüÂÄºÁöÑÂ§ÑÁêÜ„ÄÇÁõÆÂâçÊúâ‰∏ÄÁßç‰∏ªÂä®ÂºèÁöÑÊñπÈíàÈááÈõÜÊÄùË∑ØCARLA-ADAÔºåËÉΩÂ§üÂà∂Â§áÊØîËæÉÊúâÊïàÁöÑ‰ªøÁúüÊï∞ÊçÆÈõÜ„ÄÇ</li> </ul> <h1 id="3-ÁÆóÊ≥ï‰ªãÁªç">3. ÁÆóÊ≥ï‰ªãÁªç</h1> <h2 id="31-pointnet-2016">3.1 PointNet-2016</h2> <p>PointNet Âíå PointNet++ ÊúÄÊó©Ë¢´ÊèêÂá∫ÁöÑ‰∏ÄÁ±ª3DÁÇπ‰∫ëÂàÜÂâ≤Ê®°Âûã (Lidar Segmentation)Ôºå‰Ωú‰∏∫ÁÇπ‰∫ëÁõÆÊ†áÊ£ÄÊµãÁöÑÂÖàÈ©±ÂíåÂ•†Âü∫„ÄÇ</p> <h3 id="311-ÁÆóÊ≥ïÊëòË¶Å">3.1.1 ÁÆóÊ≥ïÊëòË¶Å</h3> <p>Áî±ÊñØÂù¶Á¶èÂ§ßÂ≠¶‰∫é 2016 Âπ¥ÂèëË°®ËÆ∫Êñá ‚ÄúPointNet: Deep Learning on Point Sets for 3D Classification and Segmentation‚ÄùÔºåÊòØÁÇπ‰∫ëÁ•ûÁªèÁΩëÁªúÁöÑÈºªÁ•ñÔºåÂÆÉÊèêÂá∫‰∫Ü‰∏ÄÁßçÁΩëÁªúÁªìÊûÑÔºåÂèØ‰ª•Áõ¥Êé•‰ªéÁÇπ‰∫ë‰∏≠Â≠¶‰π†ÁâπÂæÅ„ÄÇ</p> <p>ËØ•ÊñáÁ´†Âú®ÂàÜÁ±ª„ÄÅËØ≠‰πâÂàÜÂâ≤‰∏§Áßç‰ªªÂä°‰∏äÂÅöÂá∫‰∫ÜÂØπÊØîÔºåÂπ∂Áªô‰∫ÜÁêÜËÆ∫ÂíåÂÆûÈ™åÂàÜÊûê„ÄÇÁÇπ‰∫ëÁöÑÁâπÁÇπÂÖ∂ÂÆûÈùûÂ∏∏Â•ΩÁêÜËß£ÔºåÂè™Ë¶ÅÁΩëÁªúÊäì‰Ωè‰ª•‰∏ã‰∏â‰∏™ÁâπÁÇπÔºåÈÇ£‰πàÂÆÉËá≥Â∞ëÂ∞±ËÉΩ‰Ωú‰∏∫‰∏Ä‰∏™ËÉΩÁî®ÁöÑ encoder „ÄÇ</p> <ol> <li>ÊéíÂàó‰∏çÂèòÊÄßÔºöÈáçÊéí‰∏ÄÈÅçÊâÄÊúâÁÇπÁöÑËæìÂÖ•È°∫Â∫èÔºåÊâÄË°®Á§∫ÁöÑËøòÊòØÂêå‰∏Ä‰∏™ÁÇπ‰∫ëÊï∞ÊçÆÔºåÁΩëÁªúÁöÑËæìÂá∫Â∫îËØ•Áõ∏Âêå„ÄÇ</li> <li>ÁÇπÈõÜ‰πãÈó¥ÁöÑ‰∫§‰∫íÊÄßÔºöÁÇπ‰∏éÁÇπ‰πãÈó¥ÊúâÊú™Áü•ÁöÑÂÖ≥ËÅîÊÄß„ÄÇ</li> <li>ÂèòÊç¢‰∏çÂèòÊÄßÔºöÂØπ‰∫éÊüê‰∫õÂèòÊç¢Ôºå‰æãÂ¶Ç‰ªøÂ∞ÑÂèòÊç¢ÔºåÂ∫îÁî®Âú®ÁÇπ‰∫ë‰∏äÊó∂Ôºå‰∏çÂ∫îËØ•ÊîπÂèòÁΩëÁªúÂØπÁÇπ‰∫ëÁöÑÁêÜËß£„ÄÇ</li> </ol> <h3 id="312-ÂàõÊñ∞ÁÇπ">3.1.2 ÂàõÊñ∞ÁÇπ</h3> <p>Âü∫‰∫é‰ª•‰∏äÊèêÂà∞ÁöÑÁÇπ‰∫ëÊï∞ÊçÆ‰∏â‰∏™ÁâπÁÇπÔºåPointNet ÂØπÈóÆÈ¢òÁöÑÂ§ÑÁêÜÊòØÔºö</p> <ol> <li>ÊéíÂàó‰∏çÂèòÊÄßÔºöËØ•ÊñáÁ´†‰ΩøÁî®‰∫ÜÂØπÁß∞ÂáΩÊï∞ÔºàSymmetry FunctionÔºâÔºåÂÆÉÁöÑÁâπÁÇπÊòØÂØπËæìÂÖ•ÈõÜÂêàÁöÑÈ°∫Â∫è‰∏çÊïèÊÑü„ÄÇËøôÁßçÂáΩÊï∞ÈùûÂ∏∏Â§öÔºåÂ¶Ç maxpoolingÔºåÂä†Ê≥ïÔºåÂêëÈáèÁÇπÁßØÁ≠â„ÄÇPointNet ÈááÁî®ÁöÑÊòØ maxpooling ÊñπÊ≥ïÊù•ËÅöÂêàÁÇπÈõÜ‰ø°ÊÅØ„ÄÇ</li> <li>ÁÇπÈõÜ‰πãÈó¥ÁöÑ‰∫§‰∫íÊÄßÔºöÂÆûÈôÖ‰∏äÔºåÂØπÁß∞ÂáΩÊï∞ÁöÑËÅöÂêàÊìç‰ΩúÂ∞±Â∑≤ÁªèÂæóÂà∞‰∫ÜÂÖ®Â±ÄÁöÑ‰ø°ÊÅØÔºåÊ≠§Êó∂Â∞ÜÁÇπÁöÑÁâπÂæÅÂêëÈáè‰∏éÂÖ®Â±ÄÁöÑÁâπÂæÅÂêëÈáè concat Ëµ∑Êù•ÔºåÂ∞±ÂèØ‰ª•ËÆ©ÊØè‰∏™ÁÇπÊÑüÁü•Âà∞ÂÖ®Â±ÄÁöÑËØ≠‰πâ‰ø°ÊÅØ‰∫ÜÔºåÂç≥ÊâÄË∞ìÁöÑ‰∫§‰∫íÊÄß„ÄÇ</li> <li>ÂèòÊç¢‰∏çÂèòÊÄßÔºöÂè™ÈúÄË¶ÅÂØπËæìÂÖ•ÂÅö‰∏Ä‰∏™Ê†áÂáÜÂåñÊìç‰ΩúÂç≥ÂèØ„ÄÇPointNet ‰ΩøÁî®ÁΩëÁªúËÆ≠ÁªÉÂá∫‰∫Ü D Áª¥Á©∫Èó¥ÁöÑÂèòÊç¢Áü©Èòµ„ÄÇ</li> </ol> <h3 id="313-ÁΩëÁªúÁªìÊûÑ">3.1.3 ÁΩëÁªúÁªìÊûÑ</h3> <p>PointNet ÁΩëÁªúÂàÜ‰∏∫‰∏§‰∏™ÈÉ®ÂàÜÔºöÂàÜÁ±ªÁΩëÁªú (Classifiction Network) ÂíåÂàÜÂâ≤ÁΩëÁªú (Segmentation Network)„ÄÇ</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/blog/pcd-survey/pointnet-structure-480.webp 480w, /assets/img/blog/pcd-survey/pointnet-structure-800.webp 800w, /assets/img/blog/pcd-survey/pointnet-structure-1400.webp 1400w, " sizes="95vw" type="image/webp"/> <img src="/assets/img/blog/pcd-survey/pointnet-structure.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> PointNetÁÆóÊ≥ïÁΩëÁªúÁªìÊûÑ </div> <h4 id="ÂàÜÁ±ªÁΩëÁªú">ÂàÜÁ±ªÁΩëÁªú</h4> <p>Âü∫Êú¨ÊÄùË∑ØÔºöÂàÜÁ±ªÁΩëÁªú‰ª• \(n\) ‰∏™ÁÇπ‰Ωú‰∏∫ËæìÂÖ•ÔºåÂØπËæìÂÖ•ÂÅöÁâπÂæÅÂèòÊç¢ÔºàÂèòÊç¢Áü©ÈòµÔºâÔºåÂ∞ÜÁªìÊûúËæìÂÖ•Áªô MLP ÂÅöÂõûÂΩí„ÄÇÂ∞Ü‰∏ä‰∏ÄÊ≠•ÁöÑÁªìÊûúÊîæÂú®ÁâπÂæÅÁ©∫Èó¥‰∏≠ÂÅöÁâπÂæÅÂèòÊç¢ÔºåÂÜçËæìÂÖ•Áªô MLP ÂõûÂΩíÔºåÂØπÂæóÂà∞ÁöÑËæìÂá∫ËøõË°å Maxpool ÊåëÈÄâÊúÄÂ§ßÂÄºÔºå‰Ωú‰∏∫Êï¥‰∏™ 3D ÁÇπ‰∫ëÁöÑÂÖ®Â±ÄÁâπÂæÅ„ÄÇ ÂàÜÁ±ªÁΩëÁªúËÆæËÆ° Gloabl FeatureÔºåËøô‰∏ÄÊ≠•Áß∞‰∏∫ Symmetry Function for Unordered InputÔºåÂØπËæìÂÖ•ÂÅöÂ§ÑÁêÜ„ÄÇÂÖ∑‰ΩìÊù•ËÆ≤ÔºåÁî®‰∏Ä‰∏™ÁÆÄÂçïÁöÑÂØπÁß∞ÂáΩÊï∞ËÅöÈõÜÊØè‰∏™ÁÇπÁöÑ‰ø°ÊÅØÔºö</p> \[f(\{x_1,...,x_2\}) \approx g(h(x_1),...,h(x_n))\] <p>ÂØπÊ≠§ËøáÁ®ãÊï∞Â≠¶Âª∫Ê®°Ôºå\(f\)‰∏∫ÁõÆÊ†áÔºå$g$ ‰∏∫ËÆæËÆ°ÁöÑÂØπÁß∞ÂáΩÊï∞„ÄÇ‰ªéÂÖ¨ÂºèÊù•ÁúãÔºåÂÖ∂Âü∫Êú¨ÊÄùË∑ØÊòØÔºöÂØπÂêÑ‰∏™ÁÇπ\(x_k\)ÂàÜÂà´ÂÅö$h$Â§ÑÁêÜÔºåÂÜçÂ∞ÜÊâÄÊúâÂ§ÑÁêÜÂêéÁöÑÁÇπ‰∫§Áî±ÂáΩÊï∞$g$Â§ÑÁêÜÔºå‰ª•ÂÆûÁé∞ÊéíÂàó‰∏çÂèòÊÄß„ÄÇÂú®ÂÆûÁé∞‰∏≠Ôºå\(h\)‰∏∫ MLPÔºå\(g\)‰∏∫ maxpooling„ÄÇ</p> <h4 id="ÂàÜÂâ≤ÁΩëÁªú">ÂàÜÂâ≤ÁΩëÁªú</h4> <p>Âü∫Êú¨ÊÄùË∑ØÔºöÂàÜÂâ≤ÁΩëÁªúÂ∞ÜÁªèËøáÁâπÂæÅÁ©∫Èó¥ÂèòÊç¢ÂêéÁöÑÁÇπÂ±ÄÈÉ®ÁâπÂæÅ (local) ‰∏éÂÖ®Â±ÄÁâπÂæÅ (global) ÊãºÊé•ÔºåËæìÂÖ•Áªô MLP Â§ÑÁêÜÔºåÂØπÊØè‰∏Ä‰∏™ÁÇπËøõË°åÂàÜÁ±ª„ÄÇ</p> <p>ÂàÜÂâ≤ÁΩëÁªúËé∑Âèñ Point-wise FeatureÔºåËøô‰∏ÄÊ≠•Áß∞‰∏∫ Local and Global Information AggregationÔºåÂØπ‰∏§‰∏™‰∏çÂêåÁª¥Â∫¶ÁöÑÁâπÂæÅÂÅöÊãºÊé•„ÄÇ</p> <p>‰ΩÜÁî±‰∫éÁâπÂæÅÁ©∫Èó¥‰∏≠ÁöÑÂèòÊç¢Áü©ÈòµÁª¥Â∫¶ËøúËøúÂ§ß‰∫éÁ©∫Èó¥‰∏≠ÁöÑÂèòÊç¢Áü©ÈòµÁª¥Â∫¶ÔºåÂú®softmaxËÆ≠Êù•Êó∂ÔºåÁî®‰∏Ä‰∏™Ê≠£ÂàôÂåñÈ°πÔºåÂ∞ÜÁâπËøô‰∏™ÂèòÊç¢Áü©ÈòµÈôêÂà∂‰∏∫Ëøë‰ººÁöÑÊ≠£‰∫§Áü©ÈòµÔºåÂç≥ËæìÂá∫Â∞∫Â∫¶ÂΩí‰∏ÄÂåñ„ÄÇËøô‰∏ÄÊ≠•Áß∞‰∏∫ Joint Alignment NetworkÔºö</p> \[L_{reg}={||I-AA^T||}^2_F\] <p>ÂÖ∂‰∏≠\(A\)ÊòØÁª¥Â∫¶ËæÉÂ∞èÁΩëÁªúÈ¢ÑÊµãÁöÑÁâπÂæÅÂØπÈΩêÁü©Èòµ„ÄÇÊ∂àËûçÂÆûÈ™åËØÅÊòéËØ•Ê≠•È™§ÂèØ‰ª•ÊúâÊïà‰ºòÂåñÔºå‰ΩøÊ®°ÂûãÊïàÊûúÊõ¥Á®≥ÂÆö„ÄÇ</p> <h3 id="314-Ê®°ÂûãÊïàÊûú">3.1.4 Ê®°ÂûãÊïàÊûú</h3> <p>Êï∞ÊçÆÊè¥ÂºïËÆ∫ÊñáÂéüÊñáÔºåÊåáÊ†á‰∏∫ÁÇπÁöÑ mIoU(\%)„ÄÇ</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/blog/pcd-survey/pointnet%E6%95%88%E6%9E%9C-480.webp 480w, /assets/img/blog/pcd-survey/pointnet%E6%95%88%E6%9E%9C-800.webp 800w, /assets/img/blog/pcd-survey/pointnet%E6%95%88%E6%9E%9C-1400.webp 1400w, " sizes="95vw" type="image/webp"/> <img src="/assets/img/blog/pcd-survey/pointnet%E6%95%88%E6%9E%9C.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> PointNetÁÆóÊ≥ïÊïàÊûú </div> <h3 id="315-ÁÆóÊ≥ïÊÄªÁªì">3.1.5 ÁÆóÊ≥ïÊÄªÁªì</h3> <p>PointNet‰πãÊâÄ‰ª•ÂΩ±ÂìçÂäõÂ∑®Â§ßÔºåÂπ∂‰∏ç‰ªÖ‰ªÖÊòØÂõ†‰∏∫ÂÆÉÊòØÁ¨¨‰∏ÄÁØáÁÇπ‰∫ëÁõÆÊ†áÊ£ÄÊµãÊñáÁ´†ÔºåÊõ¥ÈáçË¶ÅÁöÑÊòØÂÆÉÁöÑÁΩëÁªúÂæàÁÆÄÊ¥ÅÔºàÁÆÄÊ¥Å‰∏≠Ëï¥Âê´‰∫ÜÂ§ßÈáèÁöÑÂ∑•‰ΩúÊù•Êé¢ÂØªÂá∫ÁÆÄÊ¥ÅËøôÊù°Ë∑ØÔºâÂç¥ÈùûÂ∏∏ÁöÑworkÔºåËøô‰πüÂ∞±‰ΩøÂæóÂÆÉËÉΩÂ§üÊàê‰∏∫‰∏Ä‰∏™Â∑•ÂÖ∑Ôºå‰∏Ä‰∏™‰∏∫ÁÇπ‰∫ëË°®ÂæÅÁöÑencoderÂ∑•ÂÖ∑ÔºåÂ∫îÁî®Âà∞Êõ¥ÂπøÈòîÁöÑÁÇπ‰∫ëÂ§ÑÁêÜ‰ªªÂä°‰∏≠„ÄÇ</p> <p>‰ªÖÁî® MLP+max pooling Â∞±ÂáªË¥•‰∫Ü‰ºóÂ§öSOTAÔºå‰ª§‰∫∫ÊÉäËÆ∂„ÄÇÂè¶Â§ñPointNetÂú®‰ºóÂ§öÁªÜËäÇËÆæËÆ°‰πüÈÉΩËøõË°å‰∫ÜÁêÜËÆ∫ÂàÜÊûêÂíåÊ∂àËûçÂÆûÈ™åÈ™åËØÅÔºå‰øùËØÅ‰∫Ü‰∏•Ë∞®ÊÄßÔºåËøô‰πü‰∏∫PointNetÂêéÈù¢ËÉΩÂ§üÂ§ßËßÑÊ®°Ë¢´Â∫îÁî®Êèê‰æõ‰∫ÜÊîØÊåÅ„ÄÇ</p> <p>Áî±‰∫é PointNet Ê®°ÂûãÂè™‰ΩøÁî®‰∫Ü MLP Âíå MaxpoolingÔºåÊâÄËé∑ÂæóÁöÑÁâπÂæÅÊòØÂÖ®Â±ÄÁöÑÔºåÊ≤°ÊúâÊçïËé∑Â±ÄÈÉ®ÁªìÊûÑÁâπÂú®ÔºåÂú®ÁªÜËäÇÂ§ÑÁêÜÂíåÊ≥õÁî®ÊÄßÈÉΩ‰∏çÊòØÂæàÂ•Ω„ÄÇ‰∏∫‰ΩøÂæóÁâπÂæÅÊõ¥ÂÖ≥Ê≥®‰∫é‚ÄúÂ±ÄÈÉ®‚ÄùÔºåÂØπ 3D ÁÇπ‰∫ëËøõË°åÊúâÈáçÂè†ÁöÑÂ§öÊ¨°ÈôçÈááÊ†∑ÔºåÂàÜÂà´ÂØπÊØèÊ¨°ÈááÊ†∑ÂÅöÁâπÂæÅÊèêÂèñÔºåÊúÄÂêéËøõË°åÊãºÊé•ÔºåÂÖ∂‰ΩôÊÄùË∑ØÂíå PointNet Á±ª‰ºº„ÄÇ</p> <h2 id="32-voxelnet-2017">3.2 VoxelNet-2017</h2> <h3 id="321-ÁÆóÊ≥ïÊëòË¶Å">3.2.1 ÁÆóÊ≥ïÊëòË¶Å</h3> <p>Áî± Apple ÂÖ¨Âè∏‰∫é 2017 Âπ¥ÂèëË°®ËÆ∫Êñá ‚ÄúVoxelNet: End-to-End Learning for Point Cloud Based 3D Object Detection‚ÄùÔºåÊòØ 3D ÁÇπ‰∫ëÁõÆÊ†áÊ£ÄÊµãÁúüÊ≠£Âà©Áî®Â•Ω‰ΩìÁ¥†Âåñ (Voxel) ÁöÑÁ¨¨‰∏ÄÁØáÊñáÁ´†„ÄÇ</p> <p>Âú®Ê≠§‰πãÂâçÔºå3D ÁÇπ‰∫ëÁõÆÊ†áÊ£ÄÊµãÁöÑ‰∏ªÊµÅÊñπÊ≥ïÊòØÔºö(1).Êï∞ÊçÆÈôçÁª¥Ôºö3D Êï∞ÊçÆÊäïÂΩ±Êàê 2D ÂõæÂÉèÔºåÁî®‰º†ÁªüÁõÆÊ†áÊ£ÄÊµãÊñπÊ≥ïËÆ°ÁÆó (2). Êï¥‰∏™ÁÇπ‰∫ë Voxel ÂàÜÂâ≤ÂêéÊâãÂ∑•ËÆæËÆ°ÁâπÂæÅ„ÄÇËøô‰∫õÊñπÊ≥ïÂØπÁÇπ‰∫ëÊï∞ÊçÆÁöÑÂà©Áî®‰∏çË∂≥„ÄÇ</p> <p>VoxelNet Â±û‰∫éÂçïÈò∂ÊÆµÔºåÁ´ØÂà∞Á´ØÁöÑÁÇπ‰∫ëÊ£ÄÊµã„ÄÇÂ§ßËá¥ÊµÅÁ®ã‰∏∫ÔºöÊåâÁ©∫Èó¥‰ΩçÁΩÆÂàíÂàÜ VoxelÔºåÁÑ∂ÂêéÂ∞Ü Voxel ÂÜÖÈÉ®ÁöÑÁÇπ‰∫ëËøõË°å VFE (Voxl feature encoding) ÁºñÁ†ÅÔºåÂÜçÊé•ÂÖ•RPNÊù•ÁîüÊàêÊ£ÄÊµãÁªìÊûúÔºåÂú®KITTIÊï∞ÊçÆÈõÜ‰∏äË°®Áé∞Âá∫Ëâ≤„ÄÇ</p> <h3 id="322-ÂàõÊñ∞ÁÇπ">3.2.2 ÂàõÊñ∞ÁÇπ</h3> <p>ÂØπ‰∫é VoxelNet Ê®°ÂûãÔºåÂÖ∂Á™ÅÁ†¥ÁÇπÂíåÂàõÊñ∞ÁÇπÊòØÁî® Voxel ÊèèËø∞Á©∫Èó¥Ôºå‰ΩøÁî® PointNet ÁΩëÁªúÂØπ Voxel ËøõË°åÁâπÂæÅÊèêÂèñÔºåÁî®ËØ•ÁâπÂæÅ‰ª£Ë°®ÊØè‰∏™ Voxel ÔºåÂπ∂ÊîæÂõû 3D Á©∫Èó¥‰∏≠Ôºå‰ΩøÁÇπ‰∫ëÊï∞ÊçÆÊúâÂ∫èÂåñ„ÄÇÂÆåÊàê‰∏âÁª¥ÁöÑÁ©∫Èó¥ÁöÑÁâπÂæÅÊèèËø∞ÂêéÔºåÂØπ Voxel ÂÅö‰∏âÁª¥Âç∑ÁßØÔºåÂú®ÂæóÂà∞ÁöÑÁâπÂæÅÂõæ‰∏äËøõË°åÁõÆÊ†áÊ£ÄÊµã„ÄÇÂÖ∂ÂÆûÁé∞ÊñπÂºèÂèØ‰ª•ËØ¥ÊàêÊòØÔºåÂØπÊØè‰∏™voxel‰ΩøÁî®PointNetÂæóÂà∞voxelÁöÑfeature„ÄÇ</p> <h3 id="323-ÁΩëÁªúÁªìÊûÑ">3.2.3 ÁΩëÁªúÁªìÊûÑ</h3> <p>VoxelNet ÁΩëÁªúÂàÜ‰∏∫‰∏â‰∏™Â±ÇÁ∫ßÔºöÁâπÂæÅÂ≠¶‰π†ÁΩëÁªú (Feature Learning Network)„ÄÅÂç∑ÁßØ‰∏≠Èó¥Â±Ç (Convolutional MIddle Layers)„ÄÅÂå∫ÂüüÂÄôÈÄâÁΩëÁªú (Region Proposal Network)„ÄÇ</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/blog/pcd-survey/voxelnet%E7%BB%93%E6%9E%84-480.webp 480w, /assets/img/blog/pcd-survey/voxelnet%E7%BB%93%E6%9E%84-800.webp 800w, /assets/img/blog/pcd-survey/voxelnet%E7%BB%93%E6%9E%84-1400.webp 1400w, " sizes="95vw" type="image/webp"/> <img src="/assets/img/blog/pcd-survey/voxelnet%E7%BB%93%E6%9E%84.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> VoxelNetÁÆóÊ≥ïÁΩëÁªúÁªìÊûÑ </div> <h4 id="ÁâπÂæÅÂ≠¶‰π†ÁΩëÁªú">ÁâπÂæÅÂ≠¶‰π†ÁΩëÁªú</h4> <p>ÈÄöËøá‰ª•‰∏ã‰∫î‰∏™Ê≠•È™§ÔºåÊèêÂèñÂíåÂ≠¶‰π† 3D ÁÇπ‰∫ëÊï∞ÊçÆÁâπÂæÅ„ÄÇVoxel ÂåñÁÇπ‰∫ë„ÄÅËÅöÂêàÂíåÈöèÊú∫ÈááÊ†∑ÂæàÂ•ΩÂú∞Ëß£ÂÜ≥‰∫Ü‚ÄúÊï∞ÊçÆÁÇπÊØîËæÉÁ®ÄÁñèÂíåÁ¶ªÊï£Ôºå‰∏çÂ•Ω‰ΩúÁâπÂæÅÊèêÂèñ‚ÄùÁöÑÈóÆÈ¢ò„ÄÇ</p> <ol> <li>Voxel ÂàíÂàÜÔºöÂú®Èõ∑ËææÂùêÊ†áÁ≥ª‰∏≠ÔºåÂØπ‰∫éÁ©∫Èó¥ \(D\{X,Y,Z\}\)ÔºàÈíàÂØπË¶ÅÊ£ÄÊµãÁöÑÁâ©‰ΩìÔºå‰ºöÂàáÂâ≤Âá∫‰∏çÂêåÁöÑÈïøÊñπ‰ΩìÔºâÔºåÊåâ\(V\{v_x,v_y,v_z\}\)‰∏∫Âçï‰ΩçÔºåÂàíÂàÜ‰∏∫Â∞èÁöÑVoxelÔºåÊúâ\(Z'=Z/v_z, Y'=Y/v_y, X'=X/v_x\)„ÄÇ</li> <li>ËÅöÂêàÔºöÁî±‰∫éÈõ∑ËææÊï∞ÊçÆÁöÑÁ¶ªÊï£ÊÄßÔºåÁÇπ‰∫ëÂú®‰∏âÁª¥Á©∫Èó¥ÂÜÖÁöÑÂàÜÂ∏É‰∏çÂùáÂåÄÔºå‰πüÊúâÁõ∏ÂΩìÂèØËÉΩÂá∫Áé∞Á©∫Ê£ÄÔºåÂ∞ÜÁõ∏ÈÇªÁöÑVoxelËøõË°åËÅöÂêàÔºåÂ∞ΩÈáèÂáèÂ∞ëËøôÁßçÂØπÁΩëÁªúËÆ≠ÁªÉ‰∏çÂà©ÁöÑÊÉÖÂÜµÂá∫Áé∞„ÄÇ</li> <li>ÈöèÊú∫ÈááÊ†∑ÔºöÂØπ‰∫éËÅöÂêàÂêéÁöÑVoxelÔºåÈöèÊú∫Âú®ÈùûÁ©∫ÁöÑVoxelÂÜÖÈááÊ†∑\(T\)‰∏™ÁÇπ„ÄÇËøô‰∏ÄÊ≠•ÂêéÔºåÂ∞ÜÁÇπ‰∫ëÊï∞ÊçÆË°®Á§∫‰∏∫\(\{N,T,C\}\)Ôºå\(N\)‰∏∫ÈùûÁ©∫Voxel‰∏™Êï∞Ôºå\(T\)‰∏∫ÊØè‰∏™VoxelÂÜÖÁöÑÈöèÊú∫ÈááÊ†∑ÁÇπ‰∏™Êï∞ Ôºå\(C\)‰∏∫ÁÇπÁöÑÁâπÂæÅ„ÄÇÂØπ‰∫é‰∏çË∂≥\(T\)‰∏™ÁÇπÁöÑ VoxelÔºåÈááÁî® ‚ÄúÈ´òÊñØË°•0‚Äù ÁÆóÊ≥ï„ÄÇ</li> <li>VFEÔºàVoxel Feature EnocdingÔºâÂ†ÜÂè†Ôºö <ol> <li>ÂØπ‰∫éVoxelÔºåÈ¶ñÂÖàÊï∞ÊçÆÂ¢ûÂº∫ÂÖ∂‰∏≠ÁöÑÊØè‰∏Ä‰∏™ÁÇπÔºåËÆ°ÁÆóÂπ≥ÂùáÂÄºÔºåÂÜçËÆ°ÁÆóÊØè‰∏™ÁÇπÁöÑÂÅèÁßªÈáèÔºå‰∏éÂéüÂßãÊï∞ÊçÆÊãºÊé•‰Ωú‰∏∫ËæìÂÖ•ÔºàPoint-wise InputÔºâÔºõ</li> <li>ÈááÁî®PointNetÊ®°ÂûãÁöÑÊñπÊ≥ïÔºåÂ∞ÜVoxel‰∏≠ÁöÑÁÇπÈÄöËøáÂÖ®ËøûÊé•Â±ÇÔºàFCNÔºâËΩ¨ÂåñÂà∞ÁâπÂæÅÁ©∫Èó¥ (Point-wise Feature)ÔºåÂú®Êñ∞ÁöÑÁâπÂæÅ‰∏≠ÊåëÈÄâÂá∫ÁâπÂæÅÂÄºÊúÄÂ§ßÁöÑÁÇπ (Element-wise Maxpool)Ôºå‰Ωú‰∏∫ÊØè‰∏™VoxelÁöÑË°®Èù¢ÂΩ¢Áä∂ÁâπÂæÅ (Locally Aggregated Feature)Ôºõ (c). Ëé∑ÂèñÊØè‰∏™VoxelÁöÑÁâπÂæÅÂêéÔºåÊúÄÂêéÂÜçÊãºÊé• (Point-wise Concatenate)Êàê‰∏∫Êõ¥È´òÁª¥ÁöÑÁâπÂæÅ (Point-wise concatenated Feature)„ÄÇ</li> </ol> </li> </ol> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/blog/pcd-survey/VFE-480.webp 480w, /assets/img/blog/pcd-survey/VFE-800.webp 800w, /assets/img/blog/pcd-survey/VFE-1400.webp 1400w, " sizes="95vw" type="image/webp"/> <img src="/assets/img/blog/pcd-survey/VFE.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> VFEÔºö‰ΩìÁ¥†ÁâπÂæÅÁºñÁ†ÅÂô®ÁöÑÁºñÁ†ÅËøáÁ®ã </div> <p>ÁâπÂæÅÊèêÂèñÂêéÁ®ÄÁñèÁâπÂæÅÁöÑË°®Á§∫Ôºö‰∏ä‰∏ÄÊ≠•‰∏≠ÔºåÈÉΩÊòØÂØπÈùûÁ©∫ÁöÑ voxel ËøõË°åÂ§ÑÁêÜÔºåËøô‰∫õ voxel ‰ªÖ‰ªÖÂØπÂ∫î 3D Á©∫Èó¥‰∏≠ÂæàÂ∞èÁöÑ‰∏ÄÈÉ®ÂàÜÁ©∫Èó¥„ÄÇËøôÈáåÈúÄË¶ÅÂ∞ÜÂæóÂà∞ÁöÑ N ‰∏™ÈùûÁ©∫ÁöÑ voxel ÁâπÂæÅÈáçÊñ∞Êò†Â∞ÑÂõûÊù•Ê∫êÁöÑ3DÁ©∫Èó¥‰∏≠ÔºåË°®Á§∫Êàê‰∏Ä‰∏™Á®ÄÁñèÁöÑ 4DÂº†ÈáèÔºå\(ÔºàCÔºåZ'ÔºåY'ÔºåX'Ôºâ-&gt; (128, 10, 400, 352)\)„ÄÇËøôÁßçÁ®ÄÁñèÁöÑË°®Á§∫ÊñπÊ≥ïÊûÅÂ§ßÁöÑÂáèÂ∞ë‰∫ÜÂÜÖÂ≠òÊ∂àËÄóÂíåÂèçÂêë‰º†Êí≠‰∏≠ÁöÑËÆ°ÁÆóÊ∂àËÄó„ÄÇÂêåÊó∂‰πüÊòØ VoxelNet ‰∏∫‰∫ÜÊïàÁéáËÄåÂÆûÁé∞ÁöÑÈáçË¶ÅÊ≠•È™§„ÄÇ</p> <h4 id="Âç∑ÁßØ‰∏≠Èó¥Â±Ç">Âç∑ÁßØ‰∏≠Èó¥Â±Ç</h4> <p>ÁÆÄÂçïÊù•ËÆ≤ÔºåÁî®‰ª•‰∏ã‰∏â‰∏™‰∏âÁª¥Âç∑ÁßØÊ†∏ÂØπ Voxel ÂåñÁöÑÁÇπ‰∫ëËøõË°åÂç∑ÁßØÔºåÊØè‰∏™Âç∑ÁßØÂêéÈÉΩÊé• BN Â±Ç (Batch Normalization) Âíå ReLU Â±ÇÔºåÂ¢ûÂº∫‰º†ÈÄíÈò≤Ê≠¢Ê¢ØÂ∫¶Ê∂àÂ§±ÔºåÂΩí‰∏ÄÂåñÂä†ÈÄüÁΩëÁªúÊî∂Êïõ„ÄÇÈÄöËøáÂç∑ÁßØ‰∏≠Èó¥Â±ÇÔºåËÉΩÂ§üÊèêÂçáÊÑüÂèóËßÜÈáé</p> <p>\(Conv3D_1(128, 64, 3, (2,1,1), (1,1,1))\) \(Conv3D_2(64, 64, 3, (1,1,1), (0,1,1))Ôºå\) \(Conv3D_3(64, 64, 3, (2,1,1), (1,1,1))\)</p> <p>ÈÄöËøá‰∏≠Èó¥Â±ÇËøêÁÆó‰πãÂêéÔºå4DÁöÑtensorÂ∞∫ÂØ∏‰∏∫ÔºàÊãøcar detection‰∏∫‰æãÔºå62<em>2</em>400<em>352ÔºâÔºåÁÑ∂Âêé‰ºöËøõË°åreshapeÊìç‰ΩúÔºåÂ∞ÜÁâπÂæÅÂõæÂèòÊàê 128</em>400*352‰æø‰∫éÂêéÁª≠‰ΩøÁî®RPN„ÄÇ</p> <h4 id="Âå∫ÂüüÂÄôÈÄâÂ±Ç">Âå∫ÂüüÂÄôÈÄâÂ±Ç</h4> <p>RPNÂ±ÇÁöÑÊ¶ÇÂøµÂú®FasterRCNN‰∏≠Â∞±Ë¢´ÊèêÂá∫Êù•Ôºå‰∏ªË¶ÅÊòØÁî®‰∫éÊ†πÊçÆÁâπÂæÅÂõæ‰∏≠Â≠¶‰π†Âà∞ÁöÑÁâπÂæÅÂíåÁªìÂêàanchorÊù•ÁîüÊàêÂØπÂ∫îÁöÑÈ¢ÑÊµãÁªìÊûú„ÄÇVoxelNetÁöÑÈ¢ÑÊµãÂ§¥ÔºåÁ±ª‰ºº‰∫éSSDÂíåYOLOÈÇ£‰∏ÄÁ±ªÁöÑÁõÆÊ†áÊ£ÄÊµãÁÆóÊ≥ïÁßçÁöÑÂ§¥È¢ÑÊµã„ÄÇÂú® FrCNN ‰∏≠ RPN Âú®ÊØè‰∏™ÂÉèÁ¥†ÂíåÂÉèÁ¥†ÁöÑ‰∏≠ÂøÉÁÇπ‰ΩçÁΩÆÊ†πÊçÆ anchor ÁöÑËÆæÁΩÆÔºåÈ¢ÑÊµã‰∫Ü‰∏Ä‰∏™ anchor Â±û‰∫éÁ±ªÂà´Ôºå‰ª•ÂèäÈíàÂØπËØ• anchor ÁöÑÁ≤óÂõûÂΩíË∞ÉÊï¥„ÄÇÂú®VoxelNet ‰∏≠‰πü‰∏ç‰æãÂ§ñ„ÄÇ</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/blog/pcd-survey/RPN-480.webp 480w, /assets/img/blog/pcd-survey/RPN-800.webp 800w, /assets/img/blog/pcd-survey/RPN-1400.webp 1400w, " sizes="95vw" type="image/webp"/> <img src="/assets/img/blog/pcd-survey/RPN.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> RPNÔºöÂå∫ÂüüÂÄôÈÄâÁΩëÁªúÁöÑÁâπÂæÅÂ†ÜÂè†ËøáÁ®ã </div> <p>VoxelNet ÁöÑ RPN ÁªìÊûÑÂú®ÁªèËøáÂâçÈù¢ÁöÑ Convolutional middle layers Âíå tensor ÈáçÁªÑÂæóÂà∞ÁöÑÁâπÂæÅÂõæÂêéÔºåÂØπËøô‰∏™ÁâπÂæÅÂõæÂàÜÂà´ÁöÑËøõË°å‰∫ÜÂ§öÊ¨°‰∏ãÈááÊ†∑ÔºåÁÑ∂ÂêéÂÜçÂ∞Ü‰∏çÂêå‰∏ãÈááÊ†∑ÁöÑÁâπÂæÅËøõË°åÂèçÂç∑ÁßØÊìç‰ΩúÔºåÂèòÊàêÁõ∏ÂêåÂ§ßÂ∞èÁöÑÁâπÂæÅÂõæ„ÄÇÂÜçÊãºÊé•Ëøô‰∫õÊù•Ëá™‰∏çÂêåÂ∞∫Â∫¶ÁöÑÁâπÂæÅÂõæÔºåÁî®‰∫éÊúÄÂêéÁöÑÊ£ÄÊµã„ÄÇÁªô‰∫∫ÁöÑÊÑüËßâÁ±ª‰ººÂõæÂÉèÁõÆÊ†áÊ£ÄÊµãÁöÑ NECK Ê®°Âùó‰∏≠ PANÔºåÂè™‰∏çËøáËøôÈáåÂè™Êúâ‰∏ÄÂº†ÁâπÂæÅÂõæ„ÄÇÂ∞Ü‰∏çÂêåÂ∞∫Â∫¶ÁöÑ‰ø°ÊÅØËûçÂêàÂú®‰∫Ü‰∏ÄËµ∑„ÄÇËøôÈáåÊØè‰∏ÄÂ±ÇÂç∑ÁßØÈÉΩÊòØ‰∫åÁª¥ÁöÑÂç∑ÁßØÊìç‰ΩúÔºåÊØè‰∏™Âç∑ÁßØÂêéÈù¢ÈÉΩÊé•‰∏Ä‰∏™BNÂíåRELUÂ±Ç„ÄÇËæìÂá∫ÁöÑÁªìÊûúÊòØ‰∏Ä‰∏™ÂàÜÁ±ªÈ¢ÑÊµãÂíå anchor ÂõûÂΩíÈ¢ÑÊµãÁöÑÁªìÊûú„ÄÇ</p> <h3 id="324-ÈîöÁÇπÈÄâÊã©‰∏éÊçüÂ§±ÂáΩÊï∞">3.2.4 ÈîöÁÇπÈÄâÊã©‰∏éÊçüÂ§±ÂáΩÊï∞</h3> <p>ÈîöÁÇπÁöÑÈÄâÊã©ÈááÁî®ÔºàÊãøcar detection‰∏æ‰æãÔºâÈÄâÂèñ \(l^a=3.9,w^a=1.6,h^a=1.59,z^a=-1.0,\theta=[0,90]\)„ÄÇÂÆö‰πâ\(\{a_i^{pos}\}_{i=1...N_{pos}}\)‰∏∫Ê≠£Ê†∑Êú¨ÈîöÁÇπÔºå\(\{a_i^{neg}\}_{i=1...N_{neg}}\)‰∏∫Ë¥üÊ†∑Êú¨ÈîöÁÇπ„ÄÇÊ£ÄÊµãÊ°ÜË¢´ÂèÇÊï∞ÂåñÊàê \(u=(x,y,z,l,w,h,\theta)\)„ÄÇ</p> <p>Anchol‰∏éÁúüÂÆûÂÄº‰πãÈó¥ÁöÑÂåπÈÖçÊñπÊ°à‰∏∫ÔºàÊãøcar detection‰∏æ‰æãÔºâÔºåÁúãÂÖ∂Âú®BEV‰∏ãÈù¢ÁöÑIOUÂÄºÔºåÂΩìIOUÊúÄÂ§ßÊó∂‰∏∫Ê≠£Ê†∑Êú¨ÔºåÊàñËÄÖ\(IOU &gt; 0.6\) ‰∏∫Ê≠£Ê†∑Êú¨Ôºå$IOU&lt;0.45$‰∏∫Ë¥üÊ†∑Êú¨Ôºå‰ªã‰∫é\(0.45\)‰∏é\(0.6\)‰πãÈó¥ÁöÑ‰∏¢ÂºÉÊéâ„ÄÇÊúÄÁªàÁöÑÊÆãÂ∑ÆÂΩ¢Âºè‰∏∫‰∏ãÈù¢ÁöÑÂáΩÊï∞ÔºåÂÖ∂‰∏≠Ââç‰∏§È°π‰∏∫ÂàÜÁ±ªÁöÑÊçüÂ§±ÔºåÂêé‰∏ÄÈ°π‰∏∫Ê°ÜÁöÑÊãüÂêàÁ®ãÂ∫¶ÊçüÂ§±„ÄÇ</p> \[L=\alpha\frac{1}{N_{pos}}\sum_{i}L_{cls}(P_i^{pos}, 1)+\beta\frac{1}{N_{neg}}\sum_jL_{cls}(p_j^neg, 0)+\frac{1}{N_{pos}}\sum_iL_{reg}(\textbf{u}_i,\textbf{u}_i^*)\] <p>ËÆ≠ÁªÉÊ®°ÂûãÂâçÔºåËÆ∫ÊñáÂØπÊï∞ÊçÆËøõË°å‰∫Ü‰∏ÄÂÆöÁ®ãÂ∫¶ÁöÑÊï∞ÊçÆÂ¢ûÂº∫„ÄÇÂØπÁúüÂÆûÁöÑ3DÊ†áÊ≥®Ê°ÜÔºåËøõË°åÊóãËΩ¨ÔºåÂπ≥ÁßªÔºåÂêåÊó∂ÂéªÈô§ÁöÑÁ¢∞ÊíûÁöÑÊÉÖÂÜµ„ÄÇ‰ª•ÂèäÂØπ3DÊ†áÊ≥®Ê°ÜÔºåÊï¥‰ΩìÁÇπ‰∫ëÂàÜÂà´ËøõË°å\([0.95~1.05]\)‰πãÈó¥‰∏çÂêåÁöÑÁº©Êîæ„ÄÇ</p> <h3 id="325-Ê®°ÂûãÊïàÊûú">3.2.5 Ê®°ÂûãÊïàÊûú</h3> <p>Êï∞ÊçÆÊè¥ÂºïËÆ∫ÊñáÂéüÊñáÔºåËÆ≠ÁªÉÂíåÊµãËØïÂùáÂú®KITTI‰∏äËøõË°åÔºåÊåáÊ†á‰∏∫ACC„ÄÇ</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/blog/pcd-survey/voxelnet%E6%95%88%E6%9E%9C-480.webp 480w, /assets/img/blog/pcd-survey/voxelnet%E6%95%88%E6%9E%9C-800.webp 800w, /assets/img/blog/pcd-survey/voxelnet%E6%95%88%E6%9E%9C-1400.webp 1400w, " sizes="95vw" type="image/webp"/> <img src="/assets/img/blog/pcd-survey/voxelnet%E6%95%88%E6%9E%9C.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> VoxelNetÊ®°ÂûãÂú®KITTIÊï∞ÊçÆÈõÜ‰∏äÁöÑÊïàÊûú </div> <h3 id="326-ÁÆóÊ≥ïÊÄªÁªì">3.2.6 ÁÆóÊ≥ïÊÄªÁªì</h3> <p>VoxelNet Ê®°ÂûãÂ±û‰∫éÊØîËæÉÊó©ÊúüÁöÑÂ∞ÜÁÇπ‰∫ëËΩ¨‰∏∫ Voxel ‰ΩúÂ§ÑÁêÜÁöÑÊ®°ÂûãÔºà2017ÔºâÔºåÁ™ÅÁ†¥ÊÄßÂú∞ÁúüÊ≠£ÂèëÊå• Voxel ÂàÜÂâ≤ÁÇπ‰∫ëÁöÑ‰ΩúÁî®„ÄÇÊ≠§ÂêéÔºåÂú®Ëøô‰∏™ÊÄùË∑Ø‰∏äÔºåÂØπÁÇπ‰∫ëÁõÆÊ†áÊ£ÄÊµãÁöÑÊïàÊûúËøõË°å‰∫ÜËÆ∏Â§öÊîπËøõ„ÄÇÊõ¥ÂÖ≥ÈîÆÁöÑÔºåËÆ∫ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂü∫‰∫é‰ΩìÁ¥†ÁöÑÁºñÁ†ÅÂô®VFEÔºàVoxel Feature EncoderÔºâÔºåÊó•ÂêéÂá†‰πéÊâÄÊúâÁöÑ3DÁõÆÊ†áÊ£ÄÊµãÊ®°ÂûãÈÉΩÈááÁî®VFE‰Ωú‰∏∫Â§ÑÁêÜÁÇπ‰∫ëÁöÑÁ¨¨‰∏Ä‰∏™Ê≠•È™§ÔºåËøôË∂≥‰ª•ËØ¥ÊòéVoxelNetÊâÄ‰∫ßÁîüÁöÑÂΩ±Âìç‰πãÊ∑±„ÄÇ</p> <h2 id="33-centerpoint-2021">3.3 CenterPoint-2021</h2> <h3 id="331-ËÆ∫ÊñáÊëòË¶Å">3.3.1 ËÆ∫ÊñáÊëòË¶Å</h3> <p>Áî± Utexas ‰∫é 2021 Âπ¥ÂèëË°®ËÆ∫Êñá ‚ÄúCenter-based 3D Object Detection and Tracking‚ÄùÔºåÈááÁî®Ââç‰∫∫ÊîπËøõÁöÑÈ™®Âπ≤ÁΩëÁªúÔºåÂ∞Ü2D CenterPoint ÁÆóÊ≥ïÊé®ÂπøÂà∞ 3D CenterPoint ÁÆóÊ≥ï„ÄÇ</p> <p>ÂÖ∂Âü∫Êú¨ÊÄùË∑ØÊòØÔºö1. ÁÇπ‰∫ëÊï∞ÊçÆÈÄöËøá3DÈ™®È™ºÁΩëÁªúÔºå‰ª•VoxelÁâπÂæÅÊèèËø∞ÔºåÊèêÂèñBEV‰∏ãÁöÑÁâπÂæÅÂõæÔºõ 2. Âü∫‰∫é2DÁöÑRCNNÊ£ÄÊµãÂ§¥ÂØªÊâæÁõÆÊ†á‰∏≠ÂøÉÁÇπÔºå‰ª•ÂèäËæπÊ°ÜÁöÑ3DÂ∞∫ÂØ∏Ôºå3DÊúùÂêëÔºåÈÄüÂ∫¶Ôºàstage oneÔºâÔºå‰æùÊçÆ‰∏≠ÂøÉÁÇπ‰ª•‰∏≠ÂøÉÁâπÂæÅÂõûÂΩíËøõ‰∏ÄÊ≠•‰ºòÂåñÈ¢ÑÊµãÂÄºÔºàstage twoÔºâ„ÄÇÂÖ∂Êú¨Ë¥®ÊòØ‰∏Ä‰∏™two stage, anchor freeÁöÑÁÆóÊ≥ï„ÄÇ</p> <p>Âú®nuScenes‰∏äË°®Áé∞Âá∫SOTAÊ∞¥ÂáÜÔºàNDS 65.5ÔºåAMOTA 63.8 ÔºâÔºåÂêåÊó∂Âú®waymoÊï∞ÊçÆÈõÜ‰∏äËøúÂ•Ω‰∫éÂÖ∂‰ªñÁ∫ØlidarÊñπÊ°à„ÄÇ‰ΩúËÄÖËÆ§‰∏∫Ôºå‰ΩøÁî®‰∏≠ÂøÉÁÇπË°®Á§∫ÔºåËÉΩÂ§üÂ§ßÂπÖÂáèÂ∞ë3DÊ£ÄÊµãÁöÑÈöæÂ∫¶ÔºåÂú®Â∫îÂØπ‰∏çÂêåÊúùÂêë‰∏äÊúâÂæàÂ•ΩÁöÑË°®Áé∞„ÄÇ</p> <p>È™®È™ºÁΩëÁªúÈááÁî® Voxel-Net Êàñ PointPillarÔºåÂ∞ÜÁ©∫Èó¥ÂàÜÂâ≤‰∏∫ÈïøÊù°ÂΩ¢ÁöÑVoxelÔºàPillarÔºâÔºåËæìÂÖ•ÁªôTwo-StageÊ®°ÂûãÈ¢ÑÊµã„ÄÇ</p> <h3 id="332-ÂàõÊñ∞ÁÇπ">3.3.2 ÂàõÊñ∞ÁÇπ</h3> <p>CenterPoint ÊèêÂá∫‰ΩøÁî®ÁÇπÊù•‰ª£Ë°®‰∏âÁª¥Á©∫Èó¥‰∏≠ÁöÑÁâ©‰ΩìÔºå‰ΩøÁî®‰∏Ä‰∏™ÂÖ≥ÈîÆÁÇπÊ£ÄÊµãÂô®Êù•Áâ©‰Ωì‰∏≠ÂøÉÔºå‰ª•ÂèäÂõûÂΩíÂ±ûÊÄßÔºà3D sizeÔºå3DÊúùÂêëÔºåÈÄüÂ∫¶Ôºâ„ÄÇÂú®Á¨¨‰∫åÈò∂ÊÆµÔºåÂÄüÂä©ÁÇπÁâπÂæÅÊù•Ëøõ‰∏ÄÊ≠•‰ºòÂåñËøô‰∫õ‰º∞ËÆ°„ÄÇ</p> <p>Âà©Áî®ÁÇπÁöÑË°®Á§∫ÂΩ¢ÂºèÔºåÈÅøÂÖç‰∫Ü‰∏ªÂπ≤ÁΩëÁªúÂéªÂ≠¶‰π†ÊóãËΩ¨‰∏çÂèòÊÄß„ÄÇÂêåÊó∂ÂºïÂÖ•‰∫ÜCneterNetÁÆóÊ≥ï‰∏≠ÁöÑÊ≥®ÊÑèÂäõÊú∫Âà∂ÔºåÊèêÂçáÁÆóÊ≥ïË°®Áé∞„ÄÇ</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/blog/pcd-survey/centerpoint%E6%B3%A8%E6%84%8F%E5%8A%9B-480.webp 480w, /assets/img/blog/pcd-survey/centerpoint%E6%B3%A8%E6%84%8F%E5%8A%9B-800.webp 800w, /assets/img/blog/pcd-survey/centerpoint%E6%B3%A8%E6%84%8F%E5%8A%9B-1400.webp 1400w, " sizes="95vw" type="image/webp"/> <img src="/assets/img/blog/pcd-survey/centerpoint%E6%B3%A8%E6%84%8F%E5%8A%9B.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> CenterPointÂà©Áî®‰∫ÜCenterNetÁÆóÊ≥ïÁöÑÊ≥®ÊÑèÂäõÊú∫Âà∂ </div> <p>ÁÆÄÂçïÊù•ËÆ≤ÔºåCenterPoint Áî® Voxel ÊèèËø∞Á©∫Èó¥ÔºåÁî® Point ÊèèËø∞Áâ©‰ΩìÔºõÁªìÂêà 2D ÁõÆÊ†áÊ£ÄÊµãÁªèÈ™åÔºåÂ¢ûÂä†Âçï‰ΩçÊï∞ÊçÆ‰ª∑ÂÄºÔºõÂáèÂ∞ë Voxel ËÆ°ÁÆóÈáèÔºåËøõ‰∏ÄÊ≠•Ëß£ÂÜ≥‚ÄúÊï∞ÊçÆÂ§ÑÁêÜÁÇπÂ§öÔºåÂπ≥Âùá‰∏ÄÊ¨°Êâ´ÊèèËé∑ÂèñÂá†ÂçÅ‰∏á‰∏™Êï∞ÊçÆÁÇπ‚ÄùÁöÑÈóÆÈ¢ò„ÄÇ</p> <h3 id="333-ÁΩëÁªúÁªìÊûÑ">3.3.3 ÁΩëÁªúÁªìÊûÑ</h3> <p>CenterPoint ÁΩëÁªúÂàÜ‰∏∫‰∏â‰∏™Â±ÇÁ∫ßÔºö3D È™®È™ºÁΩëÁªú (3D Backbone Network)„ÄÅÂå∫ÂüüÂÄôÈÄâÁΩëÁªú (Region Proposal Network)„ÄÅÂå∫ÂüüÂç∑ÁßØÁ•ûÁªèÁΩëÁªú (Regions with CNN features)„ÄÇ</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/blog/pcd-survey/centerpoint%E7%BB%93%E6%9E%84-480.webp 480w, /assets/img/blog/pcd-survey/centerpoint%E7%BB%93%E6%9E%84-800.webp 800w, /assets/img/blog/pcd-survey/centerpoint%E7%BB%93%E6%9E%84-1400.webp 1400w, " sizes="95vw" type="image/webp"/> <img src="/assets/img/blog/pcd-survey/centerpoint%E7%BB%93%E6%9E%84.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> CenterPointÁÆóÊ≥ïÁΩëÁªúÁªìÊûÑ </div> <h4 id="3d-È™®Âπ≤ÁΩëÁªú">3D È™®Âπ≤ÁΩëÁªú</h4> <p>ÈááÁî®È™®Âπ≤ÁΩëÁªú (VoxelNet Êàñ PointPillar)„ÄÇÊÄùË∑ØÊØîËæÉÁ±ª‰ººÔºåÂ∞Ü 3D ÁÇπ‰∫ëÂàíÂàÜ‰∏∫ VoxelÔºå‰ΩÜÂú®$Z$ÊñπÂêë‰∏ä‰∏çÂÅöÂàíÂàÜÔºåÊÑüÂÆò‰∏äÁ±ª‰ºº‰∫é‚ÄúÈïøÊù°ÂΩ¢‚ÄùÔºåÁî®ËøôÁ±ª VoxelÔºàPillarÔºâ ÊèèËø∞ÁÇπ‰∫ëÁ©∫Èó¥ÔºåÊèêÂèñÁÇπ‰∫ëÁâπÂæÅ„ÄÇ</p> <p>ÊèêÂèñÂà∞ÁöÑÁâπÂæÅÁªüÁß∞‰∏∫ map-view featureÔºå\(M\in\mathbb{R}^{W*L*F}\) (‰∏Ä‰∏™3DÁöÑTensorÔºåÁ±ªÊØîÂõæÂÉèÁöÑ\(W*H*C\)ÔºåËøôÊ†∑Â∞±Â∞±ÂèØ‰ª•ÈááÁî®ÂõæÂÉèÁöÑÊñπÊ≥ï)„ÄÇ</p> <h4 id="Â§öÁßçÊ£ÄÊµãÂ§¥---stage-one">Â§öÁßçÊ£ÄÊµãÂ§¥ - Stage One</h4> <p>3D È™®È™ºÁΩëÁªúËæìÂá∫‰∫ÜÁÇπ‰∫ëÁâπÂæÅÔºåÂú® Stage One ÈÄöËøá3ÁßçÊ£ÄÊµãÂ§¥Êù•ÂæóÂà∞ (1). center heatmap headÔºàÊ£ÄÊµã‰∏≠ÂøÉÁÇπÔºâÔºå(2).regression head ÔºàÊ£ÄÊµã‰∏≠ÂøÉÁÇπÂÅèÁßª+ËæπÊ°ÜÔºâ(3). velocity head ÔºàÊ£ÄÊµãÁõÆÊ†áÈÄüÂ∫¶Ôºâ„ÄÇ</p> <ol> <li>Center heatmap head: ‰∏é CenterNet ÊÄùË∑ØÁ±ªiÔºåÂú® backbone ÁâπÂæÅÂêéËøûÊé•‰∏Ä‰∏™ heatmap header Áî®‰∫éÈ¢ÑÊµãÁõÆÊ†á‰∏≠ÂøÉÁÇπ„ÄÇÂØπ‰∫é\(k\)‰∏™labelÔºåËæìÂá∫$k$‰∏™channel„ÄÇÈÄâÂèñ top100 ‰∏™ÁÉ≠ÂäõÂÄºÁöÑ peak ÁÇπ‰Ωú‰∏∫Ê≠£Ë¥üÊ†∑Êú¨ÁöÑÂÄôÈÄâ„ÄÇËÄÉËôëÂà∞ÁÇπ‰∫ëÊï∞ÊçÆÁ®ÄÁñèÔºåÂ∞ÜgtÁöÑÊ°ÜÊäïÂΩ±Âà∞map-view feature‰∏≠Êó∂Ôºå‰ª•gauss focal lossÁöÑÊñπÂºèÔºåÊâ©Â§ßÂØπÊØè‰∏™gtÁöÑÈ´òÊñØÊ∏êÂèòËåÉÂõ¥ÔºåÂÖ∂ÂçäÂæÑ‰∏∫\(\delta =max(f(wl),\tau)\)ÔºåÂ¢ûÂ§öÁõëÁù£Â≠¶‰π†‰∏≠ÁöÑÊ≠£Ê†∑Êú¨Êï∞Èáè„ÄÇ</li> <li>Regression head: ÂõûÂΩí‰∏≠ÂøÉÁÇπÁöÑÂÅèÂ∑ÆÔºà‰∏≠ÂøÉÁÇπÂΩíÂ±ûÁöÑvoxelÂ≠òÂú®ÂèñÊï¥ÂêéÁöÑËØØÂ∑ÆÔºâÔºå‰ª•Âèä3DBBox‰ø°ÊÅØÔºåËÆ≠ÁªÉÈò∂ÊÆµ‰ªÖÊ≠£Ê†∑Êú¨ËÆ°ÁÆóÊçüÂ§±ÔºåÊé®ÁêÜÊó∂ÈÄâÂèñ heatmap Â≥∞ÂÄºÔºåÂú® regression head ‰∏≠Ëé∑Âèñ 3D-BBox ÁöÑ‰ΩçÁΩÆ„ÄÇ</li> <li>Velocity head: È¢ÑÊµã‰∫åÁª¥ÁöÑÈÄüÂ∫¶ÔºåÁî®‰∫étrackingÔºåËøô‰∏™ÈúÄË¶ÅËæìÂÖ•ÂΩìÂâçÊó∂Âàª‰∏é‰∏ä‰∏ÄÊó∂ÂàªÁöÑmap-view featureÔºåÂè™ÂÅöÊ£ÄÊµãÂèØ‰ª•‰∏çÈááÁî®Ëøô‰∏ÄÁéØËäÇ„ÄÇÈ¢ÑÊµãÁöÑÊñπÂºèÈááÁî®Ë¥™ÂøÉÂåπÈÖçÔºàÂåàÁâôÂà©ÁÆóÊ≥ïÔºåÁ±ª‰ººSORTÔºâÔºåÂ¶ÇÊûúÁõÆÊ†áËøûÁª≠‰∏âÂ∏ßÊó†ÂåπÈÖçÔºåÂàôÂà†Èô§Êò†Â∞Ñ„ÄÇ</li> </ol> <h4 id="È¢ÑÊµã---stage-two">È¢ÑÊµã - Stage Two</h4> <p>Â∞ÜÁ¨¨‰∏ÄÈò∂ÊÆµÊ£ÄÊµãÂà∞ÁöÑ100‰∏™Ê°ÜÔºåÊØè‰∏Ä‰∏™Ê°ÜÊäïÂΩ±Âõûmap-view featureÔºåÊãøÂà∞4Êù°Ëæπ‰∏≠ÂøÉÁÇπ+1‰∏™‰∏≠ÂøÉÁÇπÔºåÂØπÂ∫îÁöÑfeatureÔºåÂ†ÜÂè†Ëµ∑Êù•„ÄÇ ‰∏∫Ëß£ÂÜ≥ÂùêÊ†áËΩ¥ÂØπÈΩêÈóÆÈ¢òÔºåÈááÁî®ÂèåÁ∫øÊÄßÊèíÂÄºÊù•Ëé∑Âèñ‰ª•‰∏äÁÇπÁöÑÁâπÂæÅ„ÄÇ ÊúÄÂêéÔºåÊï¥Âêà‰ª•‰∏ä5‰∏™ÁâπÂæÅÔºåËæìÂÖ•ÁªôMLPËÆ°ÁÆóÔºåÈ¢ÑÊµãÁΩÆ‰ø°Â∫¶ÂíåÂõûÂΩí‰ø°ÊÅØÔºåÂàÜÁ±ª‰ø°ÊÅØÂú® Stage one Â∑≤ÁªèËß£ÂÜ≥ÔºåÂæóÂà∞Â∏¶ÊúâÊñπÂêëÁöÑÈ¢ÑÊµãbbox„ÄÇ</p> <p>ÁΩÆ‰ø°Â∫¶ÊçüÂ§±ËÆ°ÁÆó: Ê£ÄÊµãÊ°ÜÁöÑÁõÆÊ†áÁΩÆ‰ø°Â∫¶ÈááÁî®‰∏ãÈù¢ÊñπÂºèËÆ°ÁÆóÔºåÂü∫Êú¨‰∏ä&gt;0.5ÂàôÁõÆÊ†áÁΩÆ‰ø°Â∫¶‰∏∫1Ôºå&lt;0.25ÂàôÁΩÆ‰ø°Â∫¶‰∏∫0ÔºåÁÑ∂ÂêéÁªìÂêà‰∫§ÂèâÁÜµÊù•ËÆ°ÁÆóÊçüÂ§±„ÄÇ</p> <p>\(L_{score}=-I_t\log(\hat{I}_t)-(1-I_t)\log(1-\hat{I}_t)\) \(I=min(1,max(0,2 \times IoU_t-0.5))\)</p> <p>Âú®Êé®ÁêÜÈò∂ÊÆµÔºåÁΩÆ‰ø°Â∫¶ÁöÑËÆ°ÁÆóÊñπÂºèÂ¶Ç‰∏ãÔºåÂÖ∂‰∏≠\(\hat{Y}_t=max_{0\le k \le K}\hat{Y}_{p, k}\)Âíå\(\hat{I}_t\)ÂàÜÂà´Ë°®Á§∫ stage one Âíå stage two ÂØπÁõÆÊ†á\(t\)ÁöÑÁΩÆ‰ø°Â∫¶„ÄÇ</p> \[\hat{Q}_t=\sqrt{\hat{Y}_t\times\hat{I}_t}\] <p>ËæπÊ°ÜÂõûÂΩíÔºöÈááÁî®NMSÔºåÂíå2DÁõÆÊ†áÊ£ÄÊµãÁöÑÊÄùË∑ØÂü∫Êú¨‰∏ÄËá¥ÔºåÂ±û‰∫éÊØîËæÉÁªèÂÖ∏ÁöÑÂÅöÊ≥ï„ÄÇ</p> <h3 id="334-Ê®°ÂûãÊïàÊûú">3.3.4 Ê®°ÂûãÊïàÊûú</h3> <p>Êï∞ÊçÆÊè¥ÂºïËÆ∫ÊñáÂéüÊñáÔºåËÆ≠ÁªÉÂíåÊµãËØïÂùáÂú®Waymo‰∏äËøõË°åÔºåÊåáÊ†á‰∏∫mAPÂíåmAPH„ÄÇ</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/blog/pcd-survey/centerpoint%E8%A1%A8%E7%8E%B0-480.webp 480w, /assets/img/blog/pcd-survey/centerpoint%E8%A1%A8%E7%8E%B0-800.webp 800w, /assets/img/blog/pcd-survey/centerpoint%E8%A1%A8%E7%8E%B0-1400.webp 1400w, " sizes="95vw" type="image/webp"/> <img src="/assets/img/blog/pcd-survey/centerpoint%E8%A1%A8%E7%8E%B0.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> CenterPointÊ®°ÂûãÂØπÊØî‰πãÂâçÁöÑÊâÄÊúâ‰∏ªÊµÅÊ®°Âûã </div> <h3 id="335-ÁÆóÊ≥ïÊÄªÁªì">3.3.5 ÁÆóÊ≥ïÊÄªÁªì</h3> <p>ÂçïÈò∂ÊÆµÁöÑÊ®°ÂûãÊïàÊûúÂæàÂ•Ω„ÄÇÂú®2021Âπ¥ËææÂà∞SOTAÊ∞¥Âπ≥ÔºàWaymoÂíånuScenesÔºâÔºåÊÄßËÉΩ‰ºò‰∫é3DSSDÔºåPointPillar„ÄÇ</p> <p>‰ΩÜËøêË°åÈÄüÂ∫¶ËæÉÊÖ¢ÔºåÂú®Titan RTX‰∏äÂÆûÈ™åÔºåWaymo 11FPSÔºå nuScenes 16FPSÔºå ÂãâÂº∫ËææÂà∞ÂÆûÊó∂ËÆ°ÁÆóË¶ÅÊ±Ç„ÄÇÈÉ®ÁΩ≤Âú®ÁúüËΩ¶‰∏ä‰ªçÈúÄË¶ÅÊîπËøõÔºàÊï∞ÊçÆÊè¥ÂºïÂéüËÆ∫ÊñáÔºâÔºõÂú®ÊúÄÊñ∞ÁöÑËÆ∫Êñá‰∏≠ÊòæÁ§∫ÔºåÂπ≥ÂùáÁöÑlatency‰∏∫96ms (CVPR2023)„ÄÇ</p> <h2 id="34-voxelnext-2023">3.4 VoxelNeXt-2023</h2> <p>Áî± CUHK ‰∫é 2023 Âπ¥3 ÊúàÂèëË°®ËÆ∫Êñá ‚ÄúVoxelNeXt: Fully Sparse VoxelNet for 3D Object Detection and Tracking‚ÄùÔºåÁúüÊ≠£Áõ¥Êé•ÈááÁî®ÁÇπ‰∫ëÊï∞ÊçÆ‰ΩúÈ¢ÑÊµã„ÄÇ</p> <h3 id="341-ÂàõÊñ∞ÁÇπ">3.4.1 ÂàõÊñ∞ÁÇπ</h3> <p>ÁõÆÂâçÁöÑ‰∏âÁª¥Ê£ÄÊµãÁΩëÁªúÔºåÈÄöÂ∏∏‰ΩøÁî®Á®ÄÁñèÂç∑ÁßØÊù•ÊèêÂèñÁâπÂæÅÔºàÂá∫‰∫éÊïàÁéáÁöÑËÄÉËôëÔºâÔºåÂÄüÈâ¥‰∫åÁª¥ÁöÑÁâ©‰ΩìÊ£ÄÊµãÁΩëÁªúÔºåÈîöÁÇπÔºåÊàñËÄÖ‰∏≠ÂøÉÁÇπÔºàCenterPointÁΩëÁªúÔºâË¢´ÊôÆÈÅçÈááÁî®„ÄÇ</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/blog/pcd-survey/voxelnext%E6%B3%A8%E6%84%8F%E5%8A%9B-480.webp 480w, /assets/img/blog/pcd-survey/voxelnext%E6%B3%A8%E6%84%8F%E5%8A%9B-800.webp 800w, /assets/img/blog/pcd-survey/voxelnext%E6%B3%A8%E6%84%8F%E5%8A%9B-1400.webp 1400w, " sizes="95vw" type="image/webp"/> <img src="/assets/img/blog/pcd-survey/voxelnext%E6%B3%A8%E6%84%8F%E5%8A%9B.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> CenterPointÊ®°ÂûãÁöÑÊ≥®ÊÑèÂäõÊ®°ÂùóÁöÑËÆ°ÁÆóÂ≠òÂú®‰∏çÂ∞ëÊÄßËÉΩÊµ™Ë¥π </div> <p>ÈîöÁÇπÊàñËÄÖ‰∏≠ÂøÉÁÇπÔºåÈÉΩÊòØ‰∏∫ÂõæÂÉèËÆæËÆ°ÁöÑÔºåÊ≤°ÊúâËÄÉËôëÂà∞ÁÇπ‰∫ëÁöÑ‰∏çËßÑÂàô‰ª•ÂèäÁ®ÄÁñèÊÄßÔºå‰∏∫‰∫ÜÂ∫îÁî®Ëøô‰∫õÊõø‰ª£ÁöÑË°®Á§∫ÊñπÊ≥ïÔºå‰∏ªÊµÅÁöÑÊ£ÄÊµãÂô®Â∞Ü‰∏âÁª¥Á®ÄÁñèÁâπÂæÅËΩ¨Êç¢Êàê‰∫åÁª¥ÁöÑÁ®†ÂØÜÁâπÂæÅÔºåÁÑ∂Âêé‰ΩøÁî®RPNÔºå‰ª•Âèä‰ΩøÁî®Á®†ÂØÜÁöÑÊ£ÄÊµãÂ§¥„ÄÇÂ∞ΩÁÆ°ÊúâÊïàÔºå‰ΩÜËøôÊ†∑‰ΩéÊïà‰ª•ÂèäÂ§çÊùÇ„ÄÇ‰ªé CenterPoint ÁöÑÁÉ≠ÂäõÂõæÂèØ‰ª•ÁúãÂá∫ÔºåÂæàÂ§öÈÉ®ÂàÜÁöÑ BEVfeature ËÆ°ÁÆóÈÉΩÊòØÊµ™Ë¥πÁöÑ„ÄÇÂêéÁª≠ËøòÈúÄË¶ÅËøõË°å NMSÊù•ÂéªÈô§ÈáçÂ§çÁöÑÊ£ÄÊµã„ÄÇ</p> <p>‰∏∫Ëß£ÂÜ≥ CenterPoint ÁÉ≠ÂäõÂõæÂíå NMS ÈáçÂ§çËÆ°ÁÆóÈóÆÈ¢òÔºåÂπ∂Ëøõ‰∏ÄÊ≠•ÂèëÊéòÊøÄÂÖâÈõ∑ËææÊï∞ÊçÆÁ®ÄÁñèÊÄßÁöÑÁâπÁÇπÔºåÊèêÂá∫ VoxelNeXt Ê®°ÂûãÔºåÈááÁî®Á∫ØÁ®ÄÁñèÁöÑ Voxel ÁΩëÁªúÔºåÁõ¥Êé•Âü∫‰∫é3DÁÇπ‰∫ëÈ¢ÑÊµãÔºåËÄå‰∏çÊòØÈÄöËøá2DÊï∞ÊçÆÂçáÁª¥È¢ÑÊµã„ÄÇÂáèÂ∞ë‰∫ÜÈùûÂ∏∏Â§öÁöÑËÆ°ÁÆóÈáèÔºåËÆ©ÂÆûÊó∂ÁöÑÈõ∑ËææÁõÆÊ†áÊ£ÄÊµãÊàê‰∏∫ÂèØËÉΩ„ÄÇ</p> <h3 id="342-ÁΩëÁªúÁªìÊûÑ">3.4.2 ÁΩëÁªúÁªìÊûÑ</h3> <p>Âú®Ê≤°Êúâ‰ªª‰ΩïÂÖ∂‰ªñÂ§çÊùÇËÆæËÆ°ÁöÑÊÉÖÂÜµ‰∏ãÔºåÈÄöËøáÈ¢ùÂ§ñÁöÑ‰∏ãÈááÊ†∑Â±ÇÂèØ‰ª•ÁÆÄÂçïÂú∞Ëß£ÂÜ≥ÊÑüÂèóÈáéÁì∂È¢à‰∏çË∂≥ÁöÑÈóÆÈ¢ò„ÄÇÁÇπ‰∫ëÊàñ‰ΩìÁ¥†ÂàÜÂ∏É‰∏çËßÑÂàôÔºåÈÄöÂ∏∏ÂàÜÊï£Âú®3DÂØπË±°ÁöÑË°®Èù¢ÔºåËÄå‰∏çÊòØ‰∏≠ÂøÉÊàñÂÜÖÈÉ®ÔºåÂõ†Ê≠§Áõ¥Êé•Âü∫‰∫é‰ΩìÁ¥†ËÄå‰∏çÊòØÊâãÂ∑•Âà∂‰ΩúÁöÑÈîöÊàñ‰∏≠ÂøÉÊù•È¢ÑÊµã3D Bbox„ÄÇ</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/blog/pcd-survey/voxelnext%E7%BB%93%E6%9E%84-480.webp 480w, /assets/img/blog/pcd-survey/voxelnext%E7%BB%93%E6%9E%84-800.webp 800w, /assets/img/blog/pcd-survey/voxelnext%E7%BB%93%E6%9E%84-1400.webp 1400w, " sizes="95vw" type="image/webp"/> <img src="/assets/img/blog/pcd-survey/voxelnext%E7%BB%93%E6%9E%84.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> ÂØπÊØî‰ª•ÂæÄÂ∏∏ËßÑÁöÑ3DÁõÆÊ†áÊ£ÄÊµãÔºåVoxelNeXtÁöÑÁΩëÁªúÁªìÊûÑÈùûÂ∏∏ÁÆÄÂçï </div> <p>VoxelNeXt ÁΩëÁªúÂåÖÂê´‰∫Ü4‰∏™ÂÆûÁé∞ÁªÜËäÇÔºö1) È™®Âπ≤ÁΩëÁªúÔºå2) Â∞Ü3DÁ®ÄÁñè‰ΩìÁ¥†ÂéãÁº©Êàê 2D Á®ÄÁñè‰ΩìÁ¥†Ôºå3ÔºâSparse max pooling / NMSÔºå4ÔºâÁî®3x3 sparse convÊàñFCÊù•È¢ÑÊµãÁâ©‰Ωì„ÄÇ</p> <h4 id="È™®Âπ≤ÁΩëÁªú">È™®Âπ≤ÁΩëÁªú</h4> <p>‰∏ÄËà¨ÊÉÖÂÜµ‰∏ãÔºåÁÆÄÂçïÁ®ÄÁñèÁöÑ CNN È™®Âπ≤ÁΩëÁªúÊúâ4‰∏™Èò∂ÊÆµÔºåÂÖ∂ÁâπÂæÅÊ≠•Èïø‰∏∫ \(\{1,2,4,8\}\)ÔºåÂ∞ÜÂÖ∂ËæìÂá∫ÁöÑÁ®ÄÁñèÁâπÂæÅÂëΩÂêç‰∏∫\(\{F_1,F_2,F_3,F_4\}\)„ÄÇÁõÆÂâçÁöÑÁâπÂæÅÊó†Ê≥ïÊèèËø∞ÂíåÈ¢ÑÊµãÔºåÂ∞§ÂÖ∂ÊòØÂ§ßÂûãÁöÑÂØπË±°ÔºàÂç†Â§ö‰∏™VoxelÔºâ„ÄÇÈ¢ùÂ§ñÂ§ö‰∏§Ê¨°‰∏ãÈááÊ†∑ÔºåÂæóÂà∞Ê≠•Èïø‰∏∫\(\{16,32\}\)ÁöÑÁâπÂæÅ\(\{F_5,F_6\}\)„ÄÇ</p> <p>Â∞ÜÊúÄÂêé‰∏â‰∏™Ê≠•È™§\(\{F_4,F_5,F_6\}\)ÁöÑÁ®ÄÁñèÁâπÂæÅËøõË°åÊãºÊé•ÔºåÂè™ÈúÄË¶Å‰ΩúÁÆÄÂçïÁöÑÁ®ÄÁñè‰∏≤ËÅîÔºåËÄå‰∏çÈúÄË¶ÅÂÖ∂‰ªñÂ§çÊùÇÁöÑÂèÇÊï∞ÂåñÂ±ÇÔºå‰ΩøÂÖ∂Á©∫Èó¥ÂØπÂÖ∂Âà∞\(F_4\)ÁâπÂæÅÁ©∫Èó¥„ÄÇÂÖ∂‰∏≠ÔºåÂØπ‰∫éÈò∂ÊÆµ$i$Ôºå$F_i$ÊòØ‰∏ÄÁªÑÂçïÁã¨ÁöÑÁâπÂæÅ\(f_p\)Ôºå\(p\in P_i\)ÊòØ 3D Á©∫Èó¥ÁöÑÁÇπÔºåÂùêÊ†á‰∏∫\(\{x_p,y_p,z_p\}\)„ÄÇ</p> <p>\(F_c=F_4\cup(F_5\cup F_6)\) \(P_6'=\{(x_p\times2^2,y_p\times2^2,z_p\times2^2) | p\in P_6 \}\) \(P_5'=\{(x_p\times2^1,y_p\times2^1,z_p\times2^1) | p\in P_6 \}\) \(P_c=P_4\cup(P_5' \cup P_6')\)</p> <p>Âú®‰∏§Ê¨°È¢ùÂ§ñ‰∏ãÈááÊ†∑‰∏ãÂÅöÁ®ÄÁñèÁâπÂæÅ‰∏≤ËÅîÂêéÔºåÊúâÊïàÊÑüÂèóËåÉÂõ¥Êâ©Â§ßÔºåÈ¢ÑÊµãÊõ¥ÂáÜÁ°ÆÔºå‰∏î‰∏çÈúÄË¶ÅÂ§™Â§öÁöÑËÆ°ÁÆó„ÄÇ</p> <h4 id="‰ΩìÁ¥†ÂéãÁº©">‰ΩìÁ¥†ÂéãÁº©</h4> <p>3D ‰ΩìÁ¥†Êò†Â∞ÑÂà∞ 2DÔºöËøô‰∏ÄÊ≠•È™§‰∏≠ÔºåÂ∞ÜÁ®ÄÁñèÁâπÂæÅËΩ¨Êç¢‰∏∫ÂØÜÈõÜÁâπÂæÅÔºåÂéãÁº©\(z\)ÊñπÂêëÔºåÂ∞Ü 3D ‰ΩìÁ¥†ÁâπÂæÅÂéãÁº©‰∏∫ÂØÜÈõÜÁöÑ 2D ÁâπÂæÅÂõæ„ÄÇVoxelNet ‰∏≠ÂèëÁé∞Ôºå2D ÁöÑÁ®ÄÁñèÁâπÂæÅÂØπÈ¢ÑÊµãÊúâÊïàÔºå‰∏çÂçïÂçïÂè™ÊòØÊäëÂà∂Ê®°ÂûãÊî∂Êïõ„ÄÇÂú® VoxelNeXt ‰∏≠ÔºåÂØπÈ´òÂ∫¶ÁöÑÂéãÁº©Âè™ÊòØ‰ª•‰ΩìÁ¥†‰∏∫ÂØπÂçï‰ΩçÔºåÊò†Â∞ÑÂú®Áªü‰∏ÄÂπ≥Èù¢‰∏äÔºåÂØπ‰∫éÂêå‰∏ÄÂå∫ÂüüÁöÑÁâπÂæÅÁ¥ØÂä†„ÄÇÊï∞Â≠¶Âª∫Ê®°‰ª•‰∏äËøáÁ®ãÔºåÂ¶Ç‰∏ãÊâÄÁ§∫Ôºö</p> <p>\(\bar{P}_c=\{(x_p,y_p)\|p\in P_c\}\) \(\bar{F}_c=\{\sum_{p\in S_{\bar{p}}}{f_p} \| \bar{p}\in\bar{P}_c\}\)</p> <p>ÂÖ∂‰∏≠\(S_{\bar{p}}=\{p\|x_p=x_{\bar{p}},y=y_{\bar{p}, p\in P_c} \}\)ÔºåÂåÖÂê´Êò†Â∞ÑÂú® 2D Âπ≥Èù¢‰∏äÁöÑ‰ΩìÁ¥†„ÄÇ</p> <p>‰ΩìÁ¥†Ë£ÅÂáèÔºöÁî±‰∫éÁΩëÁªúÂÆåÂÖ®Âü∫‰∫é‰ΩìÁ¥†Êú¨Ë∫´ÔºåËÄå 3D ÁÇπ‰∫ë‰∏≠Âê´ÊúâÂ§ßÈáèÂÜó‰ΩôÁöÑËÉåÊôØÁÇπÔºåÂØπÈ¢ÑÊµãÊúâÂæàÂ§ßÁöÑ‰∏çÂà©ÔºåÂõ†Ê≠§ÈúÄË¶ÅÂØπÊò†Â∞ÑÂêéÁöÑ 2D ‰ΩìÁ¥†ÂÅöË£ÅÂâ™„ÄÇÊ≤øÁùÄ‰∏ãÈááÊ†∑Â±ÇÈÄêÊ∏ê‰øÆÂâ™‰∏çÁõ∏ÂÖ≥ÁöÑ‰ΩìÁ¥†ÔºåÊ†πÊçÆSPS ConvÔºåÊäëÂà∂‰∫ÜÂÖ∑ÊúâÂ∞èÁâπÂæÅÈáèÂÄºÁöÑ‰ΩìÁ¥†ÁöÑËÜ®ËÉÄ„ÄÇÂ∞ÜÊäëÂà∂ÊØîËÆæ‰∏∫0.5Ôºå‰ªÖÂØπÁâπÂæÅÂπÖÂ∫¶\(\|f_p\|\)ÔºàÂú®ÈÄöÈÅìÁª¥Â∫¶‰∏äÂπ≥ÂùáÔºâÊéíÂú®Ââç‰∏ÄÂçäÁöÑ‰ΩìÁ¥†ËøõË°åÊâ©Âº†„ÄÇ</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/blog/pcd-survey/voxelnext%E4%B8%8B%E9%87%87%E6%A0%B7-480.webp 480w, /assets/img/blog/pcd-survey/voxelnext%E4%B8%8B%E9%87%87%E6%A0%B7-800.webp 800w, /assets/img/blog/pcd-survey/voxelnext%E4%B8%8B%E9%87%87%E6%A0%B7-1400.webp 1400w, " sizes="95vw" type="image/webp"/> <img src="/assets/img/blog/pcd-survey/voxelnext%E4%B8%8B%E9%87%87%E6%A0%B7.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Á±ª‰ººÈ´òÁª¥ÂêàÂπ∂ÂêéÁöÑ‰∏ãÈááÊ†∑Âºè‰ΩìÁ¥†Ë£ÅÂáè </div> <p>‰ΩìÁ¥†ÈÄâÊã©ÔºöËÆ∫ÊñáÊ≤°ÊúâÈááÁî®Â∏∏Áî®ÁöÑ NMS ÊñπÊ≥ïÔºå‰∏ç‰æùËµñ‰∫éÂØÜÈõÜÁöÑÁâπÂæÅÂõæÔºåËÄåÊòØÂü∫‰∫é3D CNNÈ™®Âπ≤ÁΩëÁªúÁöÑËæìÂá∫ËøõË°åÈ¢ÑÊµã„ÄÇÂú®ËÆ≠ÁªÉËøáÁ®ã‰∏≠ÔºåÊàë‰ª¨Â∞ÜÁ¶ªÊØè‰∏™Ê≥®ÈáäËæπÁïåÊ°Ü‰∏≠ÂøÉÊúÄËøëÁöÑ‰ΩìÁ¥†ÊåáÂÆö‰∏∫Ê≠£Ê†∑Êú¨„ÄÇÊàë‰ª¨‰ΩøÁî®ÁÑ¶ÁÇπÊçüÂ§±ËøõË°åÁõëÁù£„ÄÇ Âú®Êé®ÁêÜÊó∂ÔºåÁî±‰∫éÁâπÂæÅË∂≥Â§üÁ®ÄÁñèÔºåÂèØ‰ª•Áõ¥Êé•Áî®ÁÆÄÂçï max pooling ÈÄâÊã©ÂÖ∑ÊúâÁ©∫Èó¥Â±ÄÈÉ®ÊúÄÂ§ßÁâπÂæÅÁöÑ‰ΩìÁ¥†ÔºåËäÇÁúÅÊ£ÄÊµãÂ§¥ÁöÑËÆ°ÁÆó„ÄÇ</p> <p>ÂõûÂΩíÈ¢ÑÊµãÔºö ÂõûÂΩíÊñπÊ≥ï‰∏é CenterPoint Á±ª‰ººÔºåÁÆÄÂçïÂú∞‰ΩøÁî®Ê†∏Â§ßÂ∞è‰∏∫3ÁöÑÂÖ®ËøûÈÄöÂ±ÇÊàñ 3√ó3 Â≠êÊµÅÂΩ¢Á®ÄÁñèÂç∑ÁßØÂ±ÇËøõË°åÈ¢ÑÊµãÔºåËÄå‰∏çÈúÄË¶ÅÂÖ∂‰ªñÂ§çÊùÇÁöÑËÆæËÆ°„ÄÇËÆ∫ÊñáÂèëÁé∞Ôºå3√ó3 Á®ÄÁñèÂç∑ÁßØÊØîÂÖ®ËøûÊé•Â±Ç‰∫ßÁîüÊõ¥Â•ΩÁöÑÁªìÊûúÔºå‰ΩÜÁõÆÂâçÁº∫Â∞ëÊï∞Â≠¶‰∏äÁöÑÁêÜËÆ∫ÊîØÊíë„ÄÇ ÂêåÊ†∑ÁöÑÔºåÊâßË°å 3D Tracking ‰ªªÂä°Êó∂ÁöÑÊÄùË∑ØÂíå CenterPoint Á±ª‰ººÔºå‰ΩøÁî®‰ΩìÁ¥†ÂÖ≥ËÅîÊù•ÂåÖÂê´Êõ¥Â§ö‰∏éÊü•ËØ¢‰ΩìÁ¥†‰ΩçÁΩÆÂåπÈÖçÁöÑËΩ®ËøπÔºå‰∏çÂ§öËµòËø∞„ÄÇ</p> <h3 id="343-Ê®°ÂûãÊïàÊûú">3.4.3 Ê®°ÂûãÊïàÊûú</h3> <p>ÂØπÊØîCenterPointÔºåËÆ≠ÁªÉÂíåÊµãËØïÂú®WaymoÊï∞ÊçÆÈõÜ‰∏äÔºåÊåáÊ†á‰∏∫IoU„ÄÇ</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/blog/pcd-survey/voxelnext%E5%AF%B9%E6%AF%94centerpoint-480.webp 480w, /assets/img/blog/pcd-survey/voxelnext%E5%AF%B9%E6%AF%94centerpoint-800.webp 800w, /assets/img/blog/pcd-survey/voxelnext%E5%AF%B9%E6%AF%94centerpoint-1400.webp 1400w, " sizes="95vw" type="image/webp"/> <img src="/assets/img/blog/pcd-survey/voxelnext%E5%AF%B9%E6%AF%94centerpoint.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> VoxelNeXtËß£ÂÜ≥‰∫ÜCenterPointÊ®°Âûã‰∏≠Ê≥®ÊÑèÂäõÊµ™Ë¥πÁöÑÈÉ®ÂàÜÔºåÊÄßËÉΩÂæóÂà∞ÊèêÂçá </div> <p>ÂØπÊØî‰ª•ÂæÄÂ∏∏ËßÑÊÄùË∑ØÁöÑ3DÁÇπ‰∫ëÁõÆÊ†áÊ£ÄÊµãÁÆóÊ≥ïÔºåËÆ≠ÁªÉÂíåÊµãËØïÂú®WaymoÊï∞ÊçÆÈõÜ‰∏ä„ÄÇ</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/blog/pcd-survey/voxelnext%E8%A1%A8%E7%8E%B0-480.webp 480w, /assets/img/blog/pcd-survey/voxelnext%E8%A1%A8%E7%8E%B0-800.webp 800w, /assets/img/blog/pcd-survey/voxelnext%E8%A1%A8%E7%8E%B0-1400.webp 1400w, " sizes="95vw" type="image/webp"/> <img src="/assets/img/blog/pcd-survey/voxelnext%E8%A1%A8%E7%8E%B0.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> VoxelNeXt‰∏éÂÖ∂‰ªñÊ®°ÂûãÁöÑÊïàÊûúÂØπÊØî </div> <h3 id="344-ËÆ∫ÊñáÊÄªÁªì">3.4.4 ËÆ∫ÊñáÊÄªÁªì</h3> <p>ËÆ∫ÊñáÊÄùÊÉ≥Êù•Ê∫ê‰∫é CenterPointÔºå‰ªé 3D ÁöÑËßíÂ∫¶ËÄÉËôëÁÇπ‰∫ëÁâπÂæÅÔºåÊ≤°ÊúâÊâãÂä®ÊûÑÂª∫ËÄåÊòØÁõ¥Êé•ÈÄÅÂÖ•ÁΩëÁªúÂ≠¶‰π†ÔºåÂêåÊó∂ÂæàÂ•ΩÁöÑÂèëÊå•‰∫ÜÁÇπ‰∫ëÊï∞ÊçÆÁöÑÁ®ÄÁñèÊÄßÔºåÂáèÂ∞ëËÆ°ÁÆóÈáèÁöÑÂêåÊó∂‰ºòÂåñË°®Áé∞ÔºåÂú®Â§ö‰∏™Êï∞ÊçÆÈõÜ‰∏äÈÉΩÂÅöÂà∞SOTA„ÄÇ</p> <p>ÂÆûÈôÖË°®Áé∞ÔºåÂèØËÉΩÂú®ËÆ≠ÁªÉ‰∏äÊúâ‰∏ÄÂÆöÈöæÂ∫¶„ÄÇÁî±‰∫éÊ®°ÂûãÊú¨Ë∫´Áî±‰∫éÊ≤°ÊúâÂøΩÁï•$z$ÊñπÂêë‰∏äÁöÑ‰ø°ÊÅØÔºåÂØπÈ´òÂ∫¶ÊïèÊÑüÔºåÊòì‰∫éÂú®‰∏çÂêåÈ´òÂ∫¶‰∏äÊ£ÄÊµãÂá∫Áâ©‰Ωì„ÄÇ</p> <p>‰ΩÜÊ®°ÂûãÁöÑËÆ≠ÁªÉÂ≠òÂú®ÊØîËæÉÊòéÊòæÁöÑÈóÆÈ¢òÔºåËÆ∫Êñá‰∏≠ÈááÁî®Áü•ËØÜËí∏È¶èÁöÑÊñπÊ°àÔºåÂêåÊó∂ËÆ≠ÁªÉ‰∫ÜÊØîËæÉÈïøÁöÑÊó∂Èó¥ÔºåÂæóÂà∞‰∫ÜÊØîËæÉÂ•ΩÁöÑÈ¢ÑÊúüÁªìÊûú„ÄÇÂÆûÈôÖÂú®Êú¨Âú∞ËÆ≠ÁªÉÊó∂ÔºåËÄóÊó∂Â∑®Â§ß‰∏îÊèêÂçá‰∏çÊòéÊòæÔºåÊòØÈúÄË¶Å‰∏Ä‰∫õÈ´òÁ∫ßÁöÑÊ®°ÂûãËÆ≠ÁªÉÊñπÊ°àÊâçÂèØ‰ª•ÂæóÂà∞È¢ÑÊúüÊïàÊûúÁöÑÊ£ÄÊµãÊ®°Âûã„ÄÇ</p> <h1 id="4-ÂÆûÈ™åÂ§çÁé∞">4. ÂÆûÈ™åÂ§çÁé∞</h1> <h2 id="41-ÂÆûÈ™åËÆæËÆ°">4.1 ÂÆûÈ™åËÆæËÆ°</h2> <p>ÂáÜÂ§á‰∏§ÁªÑÊï∞ÊçÆÈõÜ\(D_{sim}\)Âíå\(D_{real}\)ÔºåÂàÜÂà´Âú®‰ªøÁúüÁéØÂ¢ÉCarlaÂíåÁúüÂÆûÁéØÂ¢ÉÔºàËÆæÂ§áVelodyne‚ÄîVLP16ÔºåÂõ≠Âå∫ÂÜÖÔºâÈááÈõÜ„ÄÇÂàÜÂà´ËÆ≠ÁªÉVoxelNet„ÄÅPointPillar„ÄÅCenterPoint‰ª•ÂèäVoxelNeXtÊ®°Âûã(epochs=160, batch size=18Ôºåsplit=0.2)„ÄÇËßÇÂØüËÆ≠ÁªÉÊó∂Èó¥‰ª•ÂèäË°®Áé∞ÊïàÊûúÔºåÊï∞ÊçÆÈõÜÁöÑËØ¶ÁªÜ‰ø°ÊÅØÂ¶Ç‰∏ãÔºö</p> <table> <thead> <tr> <th><strong>Dataset</strong></th> <th><strong>Size</strong></th> <th><strong>Frame</strong></th> <th><strong>Instances</strong></th> <th><strong>class</strong></th> <th><strong>detail</strong></th> </tr> </thead> <tbody> <tr> <td>\(D_{sim}\)</td> <td>20.03G</td> <td>3971</td> <td>75294</td> <td>Car, Truck, Van, Pedestrian, Cyclist</td> <td>city, highway</td> </tr> <tr> <td>\(D_{real}\)</td> <td>16.77G</td> <td>4068</td> <td>66329</td> <td>Vehicle, Pedestrian</td> <td>Campus</td> </tr> </tbody> </table> <h2 id="42-ÂÆûÈ™åËÆæÂ§á">4.2 ÂÆûÈ™åËÆæÂ§á</h2> <ul> <li>CPU: Intel(R) Xeon(R) CPU E5-2690 v4 @ 2.60GHz</li> <li>GPU: NVIDIA TITAN V x 6</li> <li>OS: Ubuntu 22.04.2 LTS</li> <li>MEM: 453 G</li> </ul> <h2 id="43-ÂÆûÈ™åÁªìÊûú">4.3 ÂÆûÈ™åÁªìÊûú</h2> <p>‰ª•‰∏ã‰∏∫‰ªøÁúüÊï∞ÊçÆÈõÜËØïÈ™åÁªìÊûú„ÄÇ</p> <table> <thead> <tr> <th><strong>Ê†∑Êú¨Á±ª</strong></th> <th><strong>VoxelNet</strong></th> <th><strong>PointPillar</strong></th> <th><strong>CenterPoint</strong></th> <th><strong>VoxelNeXt</strong></th> </tr> </thead> <tbody> <tr> <td>Car</td> <td>44.68</td> <td>60.28</td> <td><strong>64.09</strong></td> <td>24.09</td> </tr> <tr> <td>Truck</td> <td>52.39</td> <td><strong>71.27</strong></td> <td>68.32</td> <td>38.23</td> </tr> <tr> <td>Van</td> <td>52.46</td> <td>54.11</td> <td><strong>71.09</strong></td> <td>30.48</td> </tr> <tr> <td>Pedestrian</td> <td>30.22</td> <td>40.87</td> <td><strong>48.05</strong></td> <td>9.71</td> </tr> <tr> <td>Cyclist</td> <td>29.14</td> <td><strong>56.30</strong></td> <td>52.26</td> <td>12.33</td> </tr> <tr> <td>ËÆ≠ÁªÉÊó∂Èó¥</td> <td>3h33min</td> <td>4h17min</td> <td>5h39min</td> <td>6h13min</td> </tr> </tbody> </table> <p>‰ª•‰∏ã‰∏∫ÁúüÂÆûÈááÈõÜÊï∞ÊçÆÈõÜ‰∏ãÂÆûÈ™åÁªìÊûú„ÄÇ</p> <table> <thead> <tr> <th><strong>class</strong></th> <th><strong>VoxelNet</strong></th> <th><strong>PointPillar</strong></th> <th><strong>CenterPoint</strong></th> <th><strong>VoxelNeXt</strong></th> </tr> </thead> <tbody> <tr> <td>Vehicle</td> <td>22.03</td> <td>26.75</td> <td><strong>28.09</strong></td> <td>15.92</td> </tr> <tr> <td>Pedestrian</td> <td>9.51</td> <td>11.20</td> <td><strong>14.69</strong></td> <td>4.32</td> </tr> <tr> <td>time cost</td> <td>3h04min</td> <td>3h45min</td> <td>4h12min</td> <td>6h27min</td> </tr> </tbody> </table> <h2 id="44-ÁªìÊûúÂàÜÊûê">4.4 ÁªìÊûúÂàÜÊûê</h2> <ol> <li>Â∞±Ê®°ÂûãËÆ≠ÁªÉÊó∂Èó¥ËÄåË®ÄÔºåÈöèÁÆóÊ≥ïÂ§çÊùÇÂ∫¶ÊèêÈ´òÔºåËÆ≠ÁªÉÊó∂Èó¥ÈÄêÊ∏êÂ¢ûÂä†„ÄÇ</li> <li>Â∞±Ê®°ÂûãË°®Áé∞ÔºàmAPÔºâËÄåË®ÄÔºåÂú®‰ªøÁúüÊï∞ÊçÆÈõÜ‰∏äÔºåCenterPointÁÆóÊ≥ï‰∏éPointPillar‰∏çÁõ∏‰∏ä‰∏ã„ÄÇÂú®ÁúüÂÆûÊï∞ÊçÆÈõÜ‰∏äÔºåCenterPointÁÆóÊ≥ïË°®Áé∞ÊïàÊûúÊúÄÂ•Ω„ÄÇ</li> <li>Áî±‰∫éÁúüÂÆûÊï∞ÊçÆÈááÈõÜÊâÄÁî®ÁöÑËÆæÂ§áVelodyne-VLP16ÊòØ16Á∫øÊøÄÂÖâÈõ∑ËææÔºåÂØπ‰∫éÁõÆÊ†áÁâ©‰ΩìÁöÑÊèèËø∞Âæà‰∏çÊ∏ÖÊô∞ÔºåÂØºËá¥ËÆ≠ÁªÉÁªìÊûúÂæàÂ∑ÆÔºå‰∏é‰ªøÁúüÊï∞ÊçÆÔºà128Á∫øÊ®°ÊãüÊøÄÂÖâÈõ∑ËææÔºâÊâÄËÆ≠ÁªÉÁöÑÊ®°ÂûãË°®Áé∞Áõ∏Â∑ÆÁîöËøú„ÄÇ</li> </ol> <h1 id="5-ÊÄªÁªì">5. ÊÄªÁªì</h1> <p>‰ªéPointNetÂà∞VoxelNeXtÁÆóÊ≥ïÔºåÊøÄÂÖâÈõ∑Ëææ3DÁõÆÊ†áÊ£ÄÊµãÁÆóÊ≥ïÁöÑÂèëÂ±ïË∂äËßÅÊàêÁÜü„ÄÇ‰ªéÊèêÂá∫È™®Âπ≤ÁΩëÁªúÔºåÂà∞VFEÂíåRPNÁöÑÈ¶ñ‰∏™Â§ÑÁêÜËøáÁ®ãÔºåÂà∞ËΩ¨‰∏∫two stageÁÆóÊ≥ïÔºåÂà∞ÂºïÂÖ•Ê≥®ÊÑèÂäõÊú∫Âà∂ÔºåÊøÄÂÖâÈõ∑Ëææ3DÁõÆÊ†áÊ£ÄÊµãÁÆóÊ≥ïË∂äÊù•Ë∂äÂ§çÊùÇÔºåÊïàÊûú‰πüÈÄêÊ∏êÊèêÂçá„ÄÇÁÑ∂ËÄåÔºåÁ¶ªÊï∞ÊçÆÊú¨Ë∫´ÁöÑÁâπÂæÅÁúã‰ººÂç¥Ë∂äÊù•Ë∂äËøú„ÄÇVoxelNeXtÁöÑÊèêÂá∫Êó†ÁñëÊòØÁªôÁ†îÁ©∂ËÄÖ‰ª¨‰∏Ä‰∏™ÂæàÂ•ΩÁöÑÂêØÁ§∫‚Äî‚ÄîÂà©Áî®Â•ΩÊï∞ÊçÆÊú¨Ë∫´ÁöÑÁâπË¥®ÔºåÂç≥‰ΩøÊòØÁÆÄÂçïÁöÑÁΩëÁªúÁªìÊûÑ‰æùÁÑ∂ËÉΩÊúâÈùûÂ∏∏Â•ΩÁöÑÊïàÊûúÔºåÁúãËµ∑Êù•ÊòØÊè≠Á§∫‰∫ÜÊøÄÂÖâÈõ∑Ëææ3DÁÇπ‰∫ëÁõÆÊ†áÊ£ÄÊµãÁöÑÂèà‰∏Ä‰∏™ÂèëÂ±ïÊñ∞Ë∂ãÂäø„ÄÇ</p> <p>Êú¨ÁØáÊñáÁ´†‰ªéÊúÄÂàùÁöÑÊøÄÂÖâÈõ∑Ëææ3DÁÇπ‰∫ëÁõÆÊ†áÊ£ÄÊµãÁöÑËØûÁîüËÆ≤Ëµ∑ÔºåÂØπÂÖ∂ÂèëÂ±ïÂéÜÁ®ã‰∏≠ÁöÑÂá†‰∏™ÈáçÂ§ßÁöÑÈáåÁ®ãÁ¢ëÂºèÁöÑÁÆóÊ≥ïËøõË°å‰∫ÜËØ¶ÁªÜÁöÑ‰ªãÁªç‰∏éÂàÜÊûêÔºåÂú®Êú¨Âú∞ÈÉ®ÁΩ≤ÂíåÊµãËØïÁÆóÊ≥ïÊÄßËÉΩÔºåÊúÄÂêéÊèêÂá∫‰∫Ü‰∫õËÆ∏‰∏™‰∫∫ÁúãÊ≥ï„ÄÇÂ∏åÊúõËÉΩÂ§üÂØπÊøÄÂÖâÈõ∑Ëææ3DÁÇπ‰∫ëÁõÆÊ†áÊ£ÄÊµãÁÆóÊ≥ïÁöÑÂàùÂ≠¶ËÄÖÂ∏¶Êù•‰∏Ä‰∫õÂ∏ÆÂä©„ÄÇ</p>]]></content><author><name></name></author><category term="note"/><category term="AD"/><category term="survey"/><summary type="html"><![CDATA[Please note that it is written in Simplified Chinese]]></summary></entry></feed>